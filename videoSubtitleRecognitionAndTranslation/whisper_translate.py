#!/usr/bin/env python3
"""
è§†é¢‘å­—å¹•è¯†åˆ«ä¸ç¿»è¯‘å·¥å…·
ä½¿ç”¨Whisper mediumæ¨¡å‹è¯†åˆ«æ—¥è¯­è¯­éŸ³ï¼Œå¹¶é€šè¿‡ç™¾åº¦ç¿»è¯‘APIç”ŸæˆåŒè¯­å­—å¹•
æ”¯æŒæµ‹è¯•æ¨¡å¼ï¼ˆä»…å¤„ç†å‰10%å†…å®¹ï¼‰
"""

import os
import sys
import time
import random
import hashlib
import requests
import argparse
import subprocess
import shutil
import json
from pathlib import Path
from datetime import datetime
import whisper

def check_cpu_availability():
    """æ£€æŸ¥CPUä¿¡æ¯"""
    try:
        import psutil
        cpu_count = psutil.cpu_count(logical=False)  # ç‰©ç†æ ¸å¿ƒæ•°
        logical_cpu_count = psutil.cpu_count(logical=True)  # é€»è¾‘æ ¸å¿ƒæ•°
        memory = psutil.virtual_memory()
        memory_gb = memory.total / 1024**3
        
        return f"CPU: {cpu_count}æ ¸/{logical_cpu_count}çº¿ç¨‹, å†…å­˜: {memory_gb:.1f}GB"
    except ImportError:
        return "CPUæ¨¡å¼ï¼ˆpsutilæœªå®‰è£…ï¼Œæ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼‰"

def setup_whisper_model(model_size='medium'):
    """è®¾ç½®Whisperæ¨¡å‹ï¼ˆCPUæ¨¡å¼ï¼‰"""
    print("ğŸ’» ä½¿ç”¨CPUå¤„ç†æ¨¡å¼")
    
    # è®¾ç½®ç¼“å­˜è·¯å¾„ï¼Œé¿å…é‡å¤ä¸‹è½½
    cache_dir = os.path.expanduser('~/.cache/whisper')
    os.environ['WHISPER_CACHE_DIR'] = cache_dir
    
    print(f"ğŸ“¥ åŠ è½½Whisper {model_size}æ¨¡å‹...")
    
    # é¢„æœŸçš„æ¨¡å‹æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰- æ›´æ–°ä¸ºå®é™…å¤§å°
    expected_sizes = {
        'tiny': 75_572_083,
        'base': 142_000_000,
        'small': 466_000_000,
        'medium': 1_528_008_539,
        'large': 3_087_371_615,  # ä¿®æ­£ä¸ºå®é™…æ–‡ä»¶å¤§å°ï¼Œå¹¶ç»Ÿä¸€ä½¿ç”¨'large'ä½œä¸ºå‚æ•°
    }
    
    # æ£€æŸ¥æœ¬åœ°ç¼“å­˜
    model_file = os.path.join(cache_dir, f'{model_size}.pt')
    
    # å¯¹äºlargeæ¨¡å‹ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨large-v3.ptæ–‡ä»¶
    if model_size == 'large' and not os.path.exists(model_file):
        large_v3_file = os.path.join(cache_dir, 'large-v3.pt')
        if os.path.exists(large_v3_file):
            print(f"ğŸ”„ å‘ç°large-v3.ptæ–‡ä»¶ï¼Œåˆ›å»ºç¬¦å·é“¾æ¥ä¸ºlarge.pt")
            try:
                # åˆ›å»ºç¬¦å·é“¾æ¥æˆ–å¤åˆ¶æ–‡ä»¶
                if os.name == 'nt':  # Windowsç³»ç»Ÿ
                    import shutil
                    shutil.copy2(large_v3_file, model_file)
                else:  # Unixç³»ç»Ÿ
                    os.symlink(large_v3_file, model_file)
                print(f"âœ… å·²åˆ›å»ºlarge.ptæ–‡ä»¶")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆ›å»ºlarge.ptæ–‡ä»¶: {e}")
    
    if os.path.exists(model_file):
        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        file_size = os.path.getsize(model_file)
        expected_size = expected_sizes.get(model_size, 0)
        
        if expected_size > 0 and file_size < expected_size * 0.9:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶å¯èƒ½æŸå: {file_size:,} bytes < é¢„æœŸ {expected_size:,} bytes")
            print("ğŸ—‘ï¸ åˆ é™¤æŸåæ–‡ä»¶å¹¶é‡æ–°ä¸‹è½½...")
            try:
                os.remove(model_file)
            except Exception as e:
                print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
        else:
            print(f"âœ… ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ¨¡å‹: {model_file}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes")
    else:
        print(f"ğŸ“¡ ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜ç›®å½•: {cache_dir}")
    
    # çº¿ç¨‹å®‰å…¨çš„æ¨¡å‹åŠ è½½
    try:
        # è®¾ç½®çº¿ç¨‹å¼‚å¸¸å¤„ç†
        import threading
        threading.excepthook = lambda args: print(f"âš ï¸ çº¿ç¨‹å¼‚å¸¸: {args.exc_type.__name__}: {args.exc_value}")
        
        # åŠ è½½æ¨¡å‹
        model = whisper.load_model(model_size, device="cpu")
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        # å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹ä½œä¸ºå¤‡é€‰
        if model_size != 'tiny':
            print(f"ğŸ”„ å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹ä½œä¸ºå¤‡é€‰...")
            # æŒ‰å¤§å°é¡ºåºå°è¯•å¤‡é€‰æ¨¡å‹
            model_priority = ['medium', 'small', 'base', 'tiny']
            current_index = model_priority.index(model_size) if model_size in model_priority else 0
            
            for next_model in model_priority[current_index + 1:]:
                print(f"  å°è¯• {next_model} æ¨¡å‹...")
                try:
                    return setup_whisper_model(next_model)
                except:
                    continue
        
        # å¦‚æœæ‰€æœ‰å¤‡é€‰éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise e

# ç™¾åº¦ç¿»è¯‘APIé…ç½®
appid = '20251126002506386'
key = 'C0qK4IqU_KXjun3PhRum'

# æˆäººå†…å®¹ä¸“ä¸šæœ¯è¯­è¯å…¸
ADULT_TERMS_DICT = {
    "ãŠã£ã±ã„": "èƒ¸éƒ¨",
    "ã¡ã‚“ã¡ã‚“": "é˜´èŒ", 
    "ã¾ã‚“ã“": "é˜´é“",
    "ãƒ•ã‚§ãƒ©": "å£äº¤",
    "ä¸­å‡ºã—": "å†…å°„",
    "çµ¶é ‚": "é«˜æ½®",
    "ã‚¤ã‚¯": "é«˜æ½®",
    "æ„Ÿã˜ã‚‹": "æœ‰æ„Ÿè§‰",
    "æ°—æŒã¡ã„ã„": "èˆ’æœ",
    "ã‚‚ã£ã¨": "å†",
    "ãƒ€ãƒ¡": "ä¸è¡Œ",
    "ã‚„ã‚ã¦": "ä¸è¦",
    "ã„ã": "è¦å»äº†",
    "æ°—æŒã¡": "æ„Ÿè§‰",
    "å¥¥": "æ·±å¤„",
    "æŒ¿å…¥": "æ’å…¥",
    "ç™ºå°„": "å°„ç²¾",
    "ç²¾å­": "ç²¾æ¶²"
}

def extract_audio_segment(video_path, output_path, segment_duration=None):
    """æå–éŸ³é¢‘ç‰‡æ®µï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰"""
    print("ğŸµ æå–éŸ³é¢‘...")
    
    # ç¼–ç å®‰å…¨å¤„ç†å‡½æ•°
    def safe_subprocess_run(cmd):
        """å®‰å…¨çš„å­è¿›ç¨‹æ‰§è¡Œå‡½æ•°ï¼Œå¤„ç†ç¼–ç é—®é¢˜"""
        try:
            # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼æ•è·è¾“å‡ºï¼Œé¿å…ç¼–ç é—®é¢˜
            result = subprocess.run(cmd, shell=True, capture_output=True, text=False)
            
            # æ‰‹åŠ¨è§£ç è¾“å‡ºï¼Œå¤„ç†ç¼–ç å¼‚å¸¸
            stdout = ""
            stderr = ""
            
            if result.stdout:
                try:
                    stdout = result.stdout.decode('utf-8')
                except UnicodeDecodeError:
                    try:
                        stdout = result.stdout.decode('gbk', errors='ignore')
                    except:
                        stdout = result.stdout.decode('utf-8', errors='ignore')
            
            if result.stderr:
                try:
                    stderr = result.stderr.decode('utf-8')
                except UnicodeDecodeError:
                    try:
                        stderr = result.stderr.decode('gbk', errors='ignore')
                    except:
                        stderr = result.stderr.decode('utf-8', errors='ignore')
            
            # åˆ›å»ºæ–°çš„ç»“æœå¯¹è±¡
            class ProcessResult:
                def __init__(self, returncode, stdout, stderr):
                    self.returncode = returncode
                    self.stdout = stdout
                    self.stderr = stderr
            
            return ProcessResult(result.returncode, stdout, stderr)
            
        except Exception as e:
            print(f"âš ï¸ å­è¿›ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„ç»“æœå¯¹è±¡
            class ProcessResult:
                def __init__(self):
                    self.returncode = 1
                    self.stdout = ""
                    self.stderr = str(e)
            return ProcessResult()
    
    # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œè·å–è§†é¢‘æ€»æ—¶é•¿
    if segment_duration:
        # è·å–è§†é¢‘æ—¶é•¿
        cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "{video_path}"'
        result = safe_subprocess_run(cmd)
        
        if result.returncode == 0:
            try:
                total_duration = float(result.stdout.strip())
                test_duration = total_duration * 0.1  # 10% of total duration
                print(f"ğŸ“ è§†é¢‘æ€»æ—¶é•¿: {total_duration:.2f}ç§’ï¼Œæµ‹è¯•æ¨¡å¼æå–: {test_duration:.2f}ç§’")
                
                # æå–å‰10%çš„éŸ³é¢‘
                cmd = f'ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 -t {test_duration} -y "{output_path}"'
            except (ValueError, TypeError) as e:
                print(f"âš ï¸ æ— æ³•è§£æè§†é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤10ç§’æµ‹è¯•ç‰‡æ®µ: {e}")
                cmd = f'ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 -t 10 -y "{output_path}"'
        else:
            print("âš ï¸ æ— æ³•è·å–è§†é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤10ç§’æµ‹è¯•ç‰‡æ®µ")
            cmd = f'ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 -t 10 -y "{output_path}"'
    else:
        # æå–å®Œæ•´éŸ³é¢‘
        cmd = f'ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 -y "{output_path}"'
    
    # ä½¿ç”¨å®‰å…¨çš„å­è¿›ç¨‹æ‰§è¡Œå‡½æ•°
    result = safe_subprocess_run(cmd)
    
    if result.returncode == 0:
        print("âœ… éŸ³é¢‘æå–å®Œæˆ")
        return True
    else:
        print("âŒ éŸ³é¢‘æå–å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
        return False

def transcribe_with_whisper(audio_path, model=None, model_size='medium', language='ja', video_path=None):
    """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆCPUä¼˜åŒ–æ¨¡å¼ï¼Œæ”¯æŒè¿›åº¦æ˜¾ç¤ºå’Œæ–­ç‚¹ç»­ä¼ ï¼‰"""
    print(f"ğŸ¤ ä½¿ç”¨Whisper {model_size}æ¨¡å‹è¿›è¡Œæ—¥è¯­è¯†åˆ«...")
    
    try:
        # å¦‚æœæœªæä¾›æ¨¡å‹ï¼Œåˆ™åŠ è½½æ¨¡å‹
        if model is None:
            model = setup_whisper_model(model_size)
        
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        audio = whisper.load_audio(audio_path)
        
        # CPUä¼˜åŒ–è½¬å½•å‚æ•°
        transcription_params = {
            'audio': audio,
            'language': language,
            'task': 'transcribe',
            'word_timestamps': True,
            'temperature': 0.0,
            'best_of': 2,  # å‡å°‘å€™é€‰æ•°é‡ä»¥æé«˜é€Ÿåº¦
            'beam_size': 2,  # å‡å°‘æŸæœç´¢å¤§å°
            'fp16': False,  # CPUæ¨¡å¼ä¸‹ä¸ä½¿ç”¨fp16
            'no_speech_threshold': 0.6,  # æé«˜æ— è¯­éŸ³æ£€æµ‹é˜ˆå€¼
            'compression_ratio_threshold': 2.4  # è°ƒæ•´å‹ç¼©æ¯”é˜ˆå€¼
        }
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        print("ğŸ” è¯­éŸ³è¯†åˆ«è¿›åº¦: [" + "â–ˆ" * 0 + " " * 50 + "] 0%")
        
        # ä½¿ç”¨çº¿ç¨‹æ¥æ˜¾ç¤ºè¿›åº¦ï¼ˆåŸºäºéŸ³é¢‘æ—¶é•¿çš„æ›´å‡†ç¡®ä¼°è®¡ï¼‰
        import threading
        import time
        import os
        progress_value = 0.0
        is_running = True
        
        def progress_monitor():
            nonlocal progress_value
            
            # è·å–éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œç”¨äºæ›´å‡†ç¡®åœ°ä¼°ç®—è¿›åº¦
            try:
                file_size = os.path.getsize(audio_path)
                estimated_chunks = max(1, file_size // (1024 * 1024))  # æ¯MBä¸€ä¸ªä¼°è®¡å—
            except:
                estimated_chunks = 20  # é»˜è®¤ä¼°è®¡å—æ•°
            
            chunk_size = 1.0 / estimated_chunks
            
            while is_running and progress_value < 0.95:
                # åŸºäºæ–‡ä»¶å¤§å°çš„æ›´åˆç†è¿›åº¦ä¼°ç®—
                # å°æ–‡ä»¶å—æ•°å°‘ï¼Œè¿›åº¦å¢é•¿å¿«ï¼›å¤§æ–‡ä»¶å—æ•°å¤šï¼Œè¿›åº¦å¢é•¿æ…¢
                progress_value = min(progress_value + chunk_size, 0.95)
                progress_percent = int(progress_value * 100)
                filled_bars = int(progress_value * 50)
                empty_bars = 50 - filled_bars
                print(f"\rğŸ” è¯­éŸ³è¯†åˆ«è¿›åº¦: [" + "â–ˆ" * filled_bars + " " * empty_bars + f"] {progress_percent}%", end="", flush=True)
                
                # å¦‚æœæä¾›äº†è§†é¢‘è·¯å¾„ï¼Œå®æ—¶æ›´æ–°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶
                if video_path:
                    progress_data = {
                        'video_path': video_path,
                        'model_size': model_size,
                        'transcription_progress': progress_value,
                        'last_update_time': datetime.now().isoformat(),
                        'status': 'transcribing'
                    }
                    save_progress(video_path, progress_data)
                
                # åŠ¨æ€è°ƒæ•´æ›´æ–°é—´éš”ï¼Œå¤§æ–‡ä»¶æ›´æ–°æ›´å¿«
                update_interval = max(0.5, 3.0 - (estimated_chunks / 10))
                time.sleep(update_interval)
        
        # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
        progress_thread = threading.Thread(target=progress_monitor)
        progress_thread.daemon = True
        progress_thread.start()
        
        # è¿›è¡Œè¯­éŸ³è¯†åˆ«
        result = model.transcribe(**transcription_params)
        
        # åœæ­¢è¿›åº¦ç›‘æ§
        is_running = False
        progress_thread.join(timeout=1)
        
        # è¯†åˆ«å®Œæˆï¼Œæ›´æ–°è¿›åº¦æ˜¾ç¤º
        print(f"\rğŸ” è¯­éŸ³è¯†åˆ«è¿›åº¦: [" + "â–ˆ" * 50 + "] 100%")
        print("âœ… Whisperè¯†åˆ«å®Œæˆ")
        
        # æ›´æ–°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶
        if video_path:
            progress_data = {
                'video_path': video_path,
                'model_size': model_size,
                'transcription_result': result,
                'transcription_completed': True,
                'last_update_time': datetime.now().isoformat(),
                'status': 'completed'
            }
            save_progress(video_path, progress_data)
            print(f"ğŸ’¾ è¯†åˆ«è¿›åº¦å·²ä¿å­˜åˆ°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ Whisperè¯†åˆ«å¤±è´¥: {e}")
        
        # åœæ­¢è¿›åº¦ç›‘æ§ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
        try:
            is_running = False
        except NameError:
            pass
        
        # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶
        if video_path:
            progress_data = {
                'video_path': video_path,
                'model_size': model_size,
                'error': str(e),
                'error_time': datetime.now().isoformat(),
                'status': 'error'
            }
            save_progress(video_path, progress_data)
            print(f"ğŸ’¾ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°æ–­ç‚¹ç»­ä¼ æ–‡ä»¶")
        
        return None

def replace_adult_terms(text):
    """æ›¿æ¢æˆäººå†…å®¹ä¸“ä¸šæœ¯è¯­"""
    for jp_term, cn_term in ADULT_TERMS_DICT.items():
        text = text.replace(jp_term, cn_term)
    return text

# ç¿»è¯‘ç¼“å­˜å­—å…¸
_translation_cache = {}
_translation_cache_file = "temp/translation_cache.json"

# å°è¯•åŠ è½½ç¼“å­˜æ–‡ä»¶
try:
    import os
    if os.path.exists(_translation_cache_file):
        import json
        with open(_translation_cache_file, 'r', encoding='utf-8') as f:
            _translation_cache = json.load(f)
        print(f"âœ… å·²åŠ è½½ç¿»è¯‘ç¼“å­˜ï¼Œç¼“å­˜æ¡ç›®æ•°: {len(_translation_cache)}")
except Exception as e:
    print(f"âš ï¸  åŠ è½½ç¿»è¯‘ç¼“å­˜å¤±è´¥: {e}")
    _translation_cache = {}

def save_translation_cache():
    """ä¿å­˜ç¿»è¯‘ç¼“å­˜åˆ°æ–‡ä»¶"""
    try:
        import json
        with open(_translation_cache_file, 'w', encoding='utf-8') as f:
            json.dump(_translation_cache, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ç¿»è¯‘ç¼“å­˜å·²ä¿å­˜ï¼Œå½“å‰ç¼“å­˜æ¡ç›®æ•°: {len(_translation_cache)}")
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜ç¿»è¯‘ç¼“å­˜å¤±è´¥: {e}")

def baidu_translate(text, from_lang='jp', to_lang='zh', max_retries=3):
    """ä½¿ç”¨ç™¾åº¦ç¿»è¯‘APIç¿»è¯‘æ–‡æœ¬ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œç¼“å­˜åŠŸèƒ½ï¼‰"""
    if not appid or not key:
        print("âŒ è¯·å…ˆé…ç½®ç™¾åº¦ç¿»è¯‘APIçš„appidå’Œkey")
        return text
    
    # å¦‚æœæ–‡æœ¬ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œç›´æ¥è¿”å›
    if not text or len(text.strip()) < 2:
        return text
    
    # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦å·²ç»ä¸»è¦æ˜¯ä¸­æ–‡ï¼ˆè¶…è¿‡50%çš„å­—ç¬¦æ˜¯ä¸­æ–‡ï¼‰ï¼Œé¿å…é‡å¤ç¿»è¯‘
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    if chinese_chars > len(text) * 0.5:
        print(f"âš ï¸  æ–‡æœ¬å·²åŒ…å«å¤§é‡ä¸­æ–‡ ({chinese_chars}/{len(text)}), è·³è¿‡ç¿»è¯‘")
        return text
    
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = f"{from_lang}:{to_lang}:{text}"
    
    # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰ç¿»è¯‘ç»“æœ
    if cache_key in _translation_cache:
        cached_result = _translation_cache[cache_key]
        print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„ç¿»è¯‘ç»“æœ: {text[:20]}{'...' if len(text) > 20 else ''}")
        return cached_result
    
    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries):
        try:
            salt = str(random.randint(32768, 65536))
            sign = hashlib.md5((appid + text + salt + key).encode()).hexdigest()
            
            url = "https://fanyi-api.baidu.com/ait/api/aiTextTranslate"
            params = {
                'q': text,
                'from': from_lang,
                'to': to_lang,
                'appid': appid,
                'salt': salt,
                'sign': sign
            }
            
            # å¢åŠ è¶…æ—¶æ—¶é—´å¹¶è®¾ç½®é‡è¯•é—´éš”
            timeout = 15 + (attempt * 5)  # æ¯æ¬¡é‡è¯•å¢åŠ è¶…æ—¶æ—¶é—´
            
            # å°è¯•ä½¿ç”¨POSTè¯·æ±‚ï¼ˆæ–°APIå¯èƒ½éœ€è¦POSTï¼‰
            try:
                response = requests.post(url, data=params, timeout=timeout)
                result = response.json()
            except:
                # å¦‚æœPOSTå¤±è´¥ï¼Œå°è¯•GETè¯·æ±‚
                response = requests.get(url, params=params, timeout=timeout)
                result = response.json()
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°APIå“åº”
            print(f"ğŸ” APIå“åº”: {result}")
            
            # å¤„ç†å¤šç§å¯èƒ½çš„APIå“åº”æ ¼å¼
            translated = None
            
            # æ ¼å¼1: æ ‡å‡†ç™¾åº¦ç¿»è¯‘APIæ ¼å¼
            if 'trans_result' in result and isinstance(result['trans_result'], list):
                if result['trans_result']:
                    translated = result['trans_result'][0].get('dst', '')
            
            # æ ¼å¼2: æ–°AIç¿»è¯‘APIæ ¼å¼
            elif 'result' in result and 'trans_result' in result['result']:
                if result['result']['trans_result']:
                    translated = result['result']['trans_result'][0].get('dst', '')
            
            # æ ¼å¼3: ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœ
            elif 'dst' in result:
                translated = result['dst']
            
            # æ ¼å¼4: å…¶ä»–å¯èƒ½çš„æ ¼å¼
            elif 'translated_text' in result:
                translated = result['translated_text']
            
            if translated:
                # å¯¹ç¿»è¯‘ç»“æœè¿›è¡Œæœ¯è¯­æ›¿æ¢
                translated_result = replace_adult_terms(translated)
                
                # å°†ç¿»è¯‘ç»“æœæ·»åŠ åˆ°ç¼“å­˜
                cache_key = f"{from_lang}:{to_lang}:{text}"
                _translation_cache[cache_key] = translated_result
                
                # æ¯10ä¸ªæ–°ç¼“å­˜æ¡ç›®ä¿å­˜ä¸€æ¬¡
                if len(_translation_cache) % 10 == 0:
                    save_translation_cache()
                
                return translated_result
            else:
                error_msg = result.get('error_msg', result.get('message', result.get('error', 'æœªçŸ¥é”™è¯¯')))
                print(f"âŒ ç¿»è¯‘å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_msg}")
                
                # å¦‚æœæ˜¯APIé…é¢æˆ–è®¤è¯é—®é¢˜ï¼Œç›´æ¥è¿”å›åŸæ–‡
                if 'quota' in str(error_msg).lower() or 'appid' in str(error_msg).lower() or 'sign' in str(error_msg).lower():
                    print("âš ï¸  APIé…é¢æˆ–è®¤è¯é—®é¢˜ï¼Œç›´æ¥è¿”å›åŸæ–‡")
                    return text
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›åŸæ–‡
                if attempt == max_retries - 1:
                    print(f"âŒ ç¿»è¯‘å¤±è´¥ï¼Œæœ€å¤§é‡è¯•æ¬¡æ•°å·²è¾¾ï¼Œè¿”å›åŸæ–‡: {text}")
                    return text
                
                # ç­‰å¾…åé‡è¯•
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                
        except requests.exceptions.Timeout:
            print(f"â° ç¿»è¯‘è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            if attempt == max_retries - 1:
                return text
            time.sleep(2 ** attempt)
            
        except requests.exceptions.ConnectionError:
            print(f"ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries})")
            if attempt == max_retries - 1:
                return text
            time.sleep(2 ** attempt)
            
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return text
            time.sleep(2 ** attempt)
    
    return text


def check_translation_quality(translated_text, original_text=None):
    """æ£€æŸ¥ç¿»è¯‘è´¨é‡ï¼Œè¿”å›Trueè¡¨ç¤ºè´¨é‡è‰¯å¥½ï¼ŒFalseè¡¨ç¤ºéœ€è¦é‡è¯•"""
    # å¦‚æœç¿»è¯‘ç»“æœä¸ºç©ºï¼Œè¯´æ˜ç¿»è¯‘å¤±è´¥
    if not translated_text:
        return False
    
    # å¦‚æœæä¾›äº†åŸæ–‡ï¼Œæ£€æŸ¥æ˜¯å¦ä¸åŸæ–‡ç›¸åŒ
    if original_text and translated_text == original_text:
        return False
    
    # å¦‚æœç¿»è¯‘ç»“æœåŒ…å«å¤§é‡æ—¥æ–‡å­—ç¬¦ï¼Œè¯´æ˜ç¿»è¯‘å¯èƒ½å¤±è´¥
    japanese_chars = sum(1 for char in translated_text if 'ã€' <= char <= 'ãƒ¿')
    if japanese_chars > len(translated_text) * 0.3:  # è¶…è¿‡30%çš„æ—¥æ–‡å­—ç¬¦
        return False
    
    # å¦‚æœæä¾›äº†åŸæ–‡ï¼Œæ£€æŸ¥ç¿»è¯‘ç»“æœæ˜¯å¦è¿‡çŸ­
    if original_text and len(translated_text) < len(original_text) * 0.2:
        return False
    
    return True


def batch_translate(texts, separator="<>"):
    """æ‰¹é‡ç¿»è¯‘æ–‡æœ¬ï¼Œä½¿ç”¨æŒ‡å®šåˆ†éš”ç¬¦è¿æ¥å¤šä¸ªæ–‡æœ¬è¿›è¡Œä¸€æ¬¡ç¿»è¯‘è¯·æ±‚
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šåœ¨æ‰¹é‡ç¿»è¯‘å‰åéƒ½æ£€æŸ¥ç¼“å­˜ï¼Œæœ€å¤§åŒ–å¤ç”¨APIå“åº”ç»“æœ"""
    if not texts:
        return []
    
    # é¦–å…ˆæ£€æŸ¥æ¯ä¸ªæ–‡æœ¬æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥ä½¿ç”¨ç¼“å­˜ç»“æœ
    cached_results = []
    uncached_texts = []
    uncached_indices = []
    
    for i, text in enumerate(texts):
        if not text or len(text.strip()) < 2:
            # ç©ºæ–‡æœ¬æˆ–è¿‡çŸ­æ–‡æœ¬ç›´æ¥è¿”å›åŸå€¼
            cached_results.append((i, text))
            continue
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"jp:zh:{text}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in _translation_cache:
            cached_result = _translation_cache[cache_key]
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„ç¿»è¯‘ç»“æœ: {text[:20]}{'...' if len(text) > 20 else ''}")
            cached_results.append((i, cached_result))
        else:
            uncached_texts.append(text)
            uncached_indices.append(i)
    
    # å¦‚æœæ‰€æœ‰æ–‡æœ¬éƒ½åœ¨ç¼“å­˜ä¸­ï¼Œç›´æ¥è¿”å›ç»“æœ
    if not uncached_texts:
        print(f"ğŸ“Š æ‰¹é‡ç¿»è¯‘ç»Ÿè®¡: å…¨éƒ¨{len(texts)}ä¸ªæ–‡æœ¬å‡ä½¿ç”¨ç¼“å­˜ï¼Œæ— éœ€APIè°ƒç”¨")
        # æŒ‰åŸå§‹é¡ºåºæ’åˆ—ç»“æœ
        result_dict = dict(cached_results)
        return [result_dict[i] for i in range(len(texts))]
    
    print(f"ğŸ”„ æ‰¹é‡ç¿»è¯‘è¯·æ±‚: {len(uncached_texts)}ä¸ªæœªç¼“å­˜æ–‡æœ¬ç‰‡æ®µï¼Œæ€»é•¿åº¦: {len(separator.join(uncached_texts))}å­—ç¬¦")
    print(f"ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡: {len(cached_results)}/{len(texts)} ({len(cached_results)/len(texts)*100:.1f}%)")
    
    # ä½¿ç”¨æ›´å¯é çš„åˆ†éš”ç¬¦è¿æ¥æœªç¼“å­˜çš„æ–‡æœ¬
    batch_text = separator.join(uncached_texts)
    
    # è°ƒç”¨ç™¾åº¦ç¿»è¯‘API
    batch_result = baidu_translate(batch_text, max_retries=5)
    
    # æ ¹æ®åˆ†éš”ç¬¦åˆ†å‰²ç¿»è¯‘ç»“æœ
    translated_texts = batch_result.split(separator)
    
    # å¤„ç†åˆ†å‰²ç»“æœä¸åŒ¹é…çš„æƒ…å†µ
    if len(translated_texts) != len(uncached_texts):
        print(f"âš ï¸  æ‰¹é‡ç¿»è¯‘ç»“æœåˆ†å‰²ä¸åŒ¹é…ï¼ŒåŸå§‹: {len(uncached_texts)}ï¼Œç¿»è¯‘: {len(translated_texts)}")
        print(f"ğŸ” åŸå§‹æ–‡æœ¬: {batch_text[:100]}...")
        print(f"ğŸ” ç¿»è¯‘ç»“æœ: {batch_result[:100]}...")
        
        # æ”¹è¿›çš„åˆ†å‰²å¤±è´¥å¤„ç†ï¼šå°è¯•å¤šç§åˆ†å‰²ç­–ç•¥
        if len(translated_texts) == 1:
            # å¦‚æœåªæœ‰ä¸€ä¸ªç»“æœï¼Œå¯èƒ½æ˜¯åˆ†éš”ç¬¦è¢«ç¿»è¯‘APIå¤„ç†äº†
            print("ğŸ”„ åˆ†éš”ç¬¦å¯èƒ½è¢«APIå¤„ç†ï¼Œå°è¯•æŒ‰æ¢è¡Œç¬¦åˆ†å‰²...")
            translated_texts = batch_result.split('\n')
            
            # å¦‚æœåˆ†å‰²åæ•°é‡ä»ç„¶ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½åˆ†å‰²
            if len(translated_texts) != len(uncached_texts):
                print("ğŸ”„ ä½¿ç”¨æ™ºèƒ½åˆ†å‰²ç­–ç•¥...")
                # åŸºäºåŸæ–‡é•¿åº¦æ¯”ä¾‹è¿›è¡Œæ™ºèƒ½åˆ†å‰²
                translated_texts = smart_split_translation(batch_result, uncached_texts)
        
        # å¦‚æœæ™ºèƒ½åˆ†å‰²ä»ç„¶å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªç¿»è¯‘
        if len(translated_texts) != len(uncached_texts):
            print("ğŸ”„ åˆ†å‰²ç­–ç•¥å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªç¿»è¯‘...")
            individual_translations = []
            for text in uncached_texts:
                translated = baidu_translate(text, max_retries=3)
                individual_translations.append(translated)
            translated_texts = individual_translations
    else:
        print(f"âœ… æ‰¹é‡ç¿»è¯‘åˆ†å‰²æˆåŠŸ: {len(translated_texts)}ä¸ªç»“æœå®Œç¾åŒ¹é…")
    
    # ç»„åˆç¼“å­˜ç»“æœå’Œæ–°ç¿»è¯‘ç»“æœ
    result_dict = dict(cached_results)
    for i, (original_index, translated_text) in enumerate(zip(uncached_indices, translated_texts)):
        result_dict[original_index] = translated_text
        # è®°å½•æ¯ä¸ªç¿»è¯‘ç»“æœçš„è¯¦ç»†ä¿¡æ¯
        original_text = texts[original_index]
        print(f"   ğŸ“ ç¿»è¯‘ç»“æœ {i+1}/{len(uncached_texts)}: ")
        print(f"     åŸæ–‡: {original_text}")
        print(f"     ç¿»è¯‘: {translated_text}")
    
    # æŒ‰åŸå§‹é¡ºåºæ’åˆ—ç»“æœ
    final_results = [result_dict[i] for i in range(len(texts))]
    
    print(f"ğŸ“Š æ‰¹é‡ç¿»è¯‘å®Œæˆ: æ€»è®¡{len(texts)}ä¸ªæ–‡æœ¬ï¼Œç¼“å­˜å‘½ä¸­{len(cached_results)}ä¸ªï¼ŒAPIç¿»è¯‘{len(uncached_texts)}ä¸ª")
    
    return final_results

def smart_split_translation(translated_text, original_texts):
    """æ™ºèƒ½åˆ†å‰²ç¿»è¯‘ç»“æœï¼ŒåŸºäºåŸæ–‡é•¿åº¦æ¯”ä¾‹è¿›è¡Œåˆ†å‰²"""
    if not translated_text or not original_texts:
        return []
    
    # è®¡ç®—åŸæ–‡æ€»é•¿åº¦
    total_original_length = sum(len(text) for text in original_texts)
    if total_original_length == 0:
        return [translated_text] * len(original_texts)
    
    # åŸºäºåŸæ–‡é•¿åº¦æ¯”ä¾‹è¿›è¡Œåˆ†å‰²
    split_results = []
    current_pos = 0
    
    for i, original_text in enumerate(original_texts):
        if i == len(original_texts) - 1:
            # æœ€åä¸€ä¸ªæ–‡æœ¬ï¼Œå–å‰©ä½™æ‰€æœ‰å†…å®¹
            split_results.append(translated_text[current_pos:].strip())
        else:
            # åŸºäºæ¯”ä¾‹è®¡ç®—åˆ†å‰²ä½ç½®
            ratio = len(original_text) / total_original_length
            split_pos = int(len(translated_text) * ratio)
            
            # å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹ï¼ˆæ ‡ç‚¹ç¬¦å·é™„è¿‘ï¼‰
            actual_split_pos = find_best_split_point(translated_text, current_pos + split_pos)
            
            split_results.append(translated_text[current_pos:actual_split_pos].strip())
            current_pos = actual_split_pos
    
    return split_results

def find_best_split_point(text, target_pos):
    """åœ¨ç›®æ ‡ä½ç½®é™„è¿‘å¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹ï¼ˆæ ‡ç‚¹ç¬¦å·é™„è¿‘ï¼‰"""
    if target_pos >= len(text):
        return len(text)
    
    # æ ‡ç‚¹ç¬¦å·åˆ—è¡¨
    punctuation = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼Œ', 'ï¼›', 'ï¼š', '.', '!', '?', ',', ';', ':', 'ã€']
    
    # åœ¨ç›®æ ‡ä½ç½®é™„è¿‘å¯»æ‰¾æ ‡ç‚¹ç¬¦å·
    search_range = min(50, len(text) - target_pos)  # æœç´¢èŒƒå›´é™åˆ¶
    
    # å‘åæœç´¢
    for i in range(target_pos, min(target_pos + search_range, len(text))):
        if text[i] in punctuation:
            return i + 1  # åœ¨æ ‡ç‚¹ç¬¦å·ååˆ†å‰²
    
    # å‘å‰æœç´¢
    for i in range(target_pos, max(0, target_pos - search_range), -1):
        if text[i] in punctuation:
            return i + 1  # åœ¨æ ‡ç‚¹ç¬¦å·ååˆ†å‰²
    
    # å¦‚æœæ‰¾ä¸åˆ°æ ‡ç‚¹ç¬¦å·ï¼Œåœ¨ç©ºæ ¼å¤„åˆ†å‰²
    for i in range(target_pos, min(target_pos + search_range, len(text))):
        if text[i] == ' ':
            return i + 1
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›ç›®æ ‡ä½ç½®
    return target_pos

def generate_bilingual_subtitle_file(transcription_result, output_path, video_path=None, adult_content=False):
    """ç”ŸæˆåŒè¯­å­—å¹•æ–‡ä»¶ï¼ˆæ—¥è¯­+ä¸­æ–‡ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå®æ—¶è¿›åº¦æ˜¾ç¤ºï¼‰"""
    print("ğŸ“ ç”ŸæˆåŒè¯­å­—å¹•æ–‡ä»¶...")
    print("ğŸŒ ä½¿ç”¨ç™¾åº¦ç¿»è¯‘APIç¿»è¯‘æ—¥è¯­åˆ°ä¸­æ–‡...")
    print("ğŸ¨ å­—å¹•æ ·å¼: æ—¥è¯­(12å·é‡‘è‰²) + ä¸­æ–‡(16å·ç™½è‰²)")
    print("âš¡ å¯ç”¨ä¼˜åŒ–çš„æ‰¹é‡ç¿»è¯‘åŠŸèƒ½ï¼Œæœ€å¤§åŒ–å¤ç”¨APIå“åº”ç»“æœ")
    
    try:
        segments = transcription_result.get('segments', [])
        total_segments = len(segments)
        
        if total_segments == 0:
            print("âš ï¸  æ²¡æœ‰å¯ç¿»è¯‘çš„ç‰‡æ®µ")
            return False
        
        # åŠ è½½è¿›åº¦ï¼ˆå¦‚æœæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        start_index = 0
        srt_content = ""
        
        if video_path:
            progress = load_progress(video_path)
            if progress:
                # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                if progress.get('completed', False):
                    print(f"âœ… æ£€æµ‹åˆ°å·²å®Œæˆçš„ç¿»è¯‘è¿›åº¦ï¼Œç›´æ¥ä½¿ç”¨ä¿å­˜çš„ç»“æœ")
                    if 'srt_content' in progress:
                        srt_content = progress['srt_content']
                        # ç›´æ¥å†™å…¥æ–‡ä»¶å¹¶è¿”å›æˆåŠŸ
                        with open(output_path, 'w', encoding='utf-8') as f:
                            f.write(srt_content)
                        print(f"âœ… åŒè¯­å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
                        return True
                
                # åŠ è½½ç¿»è¯‘è¿›åº¦
                last_translated = progress.get('last_translated_index', 0)
                saved_srt = progress.get('srt_content', "")
                
                # éªŒè¯è¿›åº¦çš„æœ‰æ•ˆæ€§
                if 0 <= last_translated <= total_segments:
                    start_index = last_translated
                    # åªæœ‰å½“ç´¢å¼•å¤§äº0æ—¶æ‰ä½¿ç”¨ä¿å­˜çš„SRTå†…å®¹ï¼ˆé¿å…ä½¿ç”¨ç©ºå†…å®¹è¦†ç›–ï¼‰
                    if start_index > 0 and saved_srt.strip():
                        srt_content = saved_srt
                        print(f"ğŸ”„ ä»æ–­ç‚¹ç»§ç»­: å·²ç¿»è¯‘ {start_index}/{total_segments} ä¸ªç‰‡æ®µ")
                    else:
                        print("ğŸ”„ é‡æ–°å¼€å§‹ç¿»è¯‘: è¿›åº¦æ–‡ä»¶ä¸­çš„å†…å®¹æ— æ•ˆæˆ–ä¸ºç©º")
                else:
                    print(f"âš ï¸ æ£€æµ‹åˆ°æ— æ•ˆçš„è¿›åº¦ç´¢å¼•: {last_translated}ï¼Œé‡æ–°å¼€å§‹ç¿»è¯‘")
        
        # æ˜¾ç¤ºè¿›åº¦æ¡åˆå§‹åŒ–
        print("ğŸ“Š ç¿»è¯‘è¿›åº¦: [" + " " * 50 + "] 0%")
        
        # æ‰¹é‡ç¿»è¯‘è®¾ç½®
        MAX_CHARS_PER_BATCH = 5000  # ç™¾åº¦ç¿»è¯‘APIé™åˆ¶6000å­—ç¬¦ï¼Œè®¾ç½®5000ç•™æœ‰ä½™åœ°
        separator = "<>"  # æ‰¹é‡ç¿»è¯‘åˆ†éš”ç¬¦
        
        # ç”ŸæˆåŒè¯­SRTæ ¼å¼å­—å¹•
        i = start_index
        while i < total_segments:
            # å‡†å¤‡æ‰¹é‡ç¿»è¯‘çš„æ–‡æœ¬ï¼ˆåŸºäºå­—ç¬¦æ•°é™åˆ¶ï¼‰
            batch_segments = []
            batch_japanese_texts = []
            valid_indices = []
            current_char_count = 0
            
            # æ”¶é›†ä¸è¶…è¿‡å­—ç¬¦é™åˆ¶çš„æ–‡æœ¬
            for j in range(i, total_segments):
                segment = segments[j]
                japanese_text = segment['text'].strip()
                
                # è®¡ç®—æ·»åŠ è¿™ä¸ªæ–‡æœ¬åå¯èƒ½çš„æ€»å­—ç¬¦æ•°ï¼ˆåŒ…æ‹¬åˆ†éš”ç¬¦ï¼‰
                segment_char_count = len(japanese_text)
                if batch_japanese_texts:  # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œéœ€è¦åŠ ä¸Šåˆ†éš”ç¬¦
                    segment_char_count += len(separator)
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡å­—ç¬¦é™åˆ¶
                if current_char_count + segment_char_count > MAX_CHARS_PER_BATCH:
                    break
                
                # æ·»åŠ åˆ°æ‰¹æ¬¡
                batch_segments.append(segment)
                if japanese_text:  # åªå¤„ç†éç©ºæ–‡æœ¬
                    batch_japanese_texts.append(japanese_text)
                    valid_indices.append(len(batch_japanese_texts) - 1)
                else:
                    valid_indices.append(-1)  # æ ‡è®°ä¸ºç©ºæ–‡æœ¬
                
                # æ›´æ–°å­—ç¬¦è®¡æ•°
                current_char_count += segment_char_count
            
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»“æŸç´¢å¼•
            batch_end = i + len(batch_segments)
            
            # æ‰§è¡Œæ‰¹é‡ç¿»è¯‘
            if batch_japanese_texts:
                print(f"\nğŸ“¦ æ‰¹é‡ç¿»è¯‘æ‰¹æ¬¡ {i//len(batch_segments)+1}: å¤„ç†{len(batch_segments)}ä¸ªç‰‡æ®µ")
                batch_chinese_texts = batch_translate(batch_japanese_texts, separator)
                
                # å¤„ç†æ¯ä¸ªç¿»è¯‘ç»“æœ
                for idx, segment in enumerate(batch_segments):
                    global_index = i + idx
                    start_time = format_time(segment['start'])
                    end_time = format_time(segment['end'])
                    japanese_text = segment['text'].strip()
                    
                    if valid_indices[idx] != -1 and valid_indices[idx] < len(batch_chinese_texts):
                        chinese_text = batch_chinese_texts[valid_indices[idx]]
                        
                        # æ£€æŸ¥ç¿»è¯‘è´¨é‡
                        if not check_translation_quality(chinese_text, japanese_text):
                            print(f"âš ï¸  ç¿»è¯‘è´¨é‡ä¸ä½³ï¼Œå•ç‹¬é‡è¯•ç‰‡æ®µ {global_index+1}...")
                            print(f"ğŸ“Š å•ç‹¬ç¿»è¯‘ç»Ÿè®¡: ç¬¬{global_index+1}ä¸ªç‰‡æ®µè´¨é‡æ£€æŸ¥å¤±è´¥ï¼Œå¯åŠ¨å•ç‹¬ç¿»è¯‘")
                            
                            # ç”Ÿæˆç¼“å­˜é”®
                            cache_key = f"jp:zh:{japanese_text}"
                            
                            # æ£€æŸ¥ç¼“å­˜
                            if cache_key in _translation_cache:
                                chinese_text = _translation_cache[cache_key]
                                print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„ç¿»è¯‘ç»“æœ")
                                print(f"ğŸ“Š å•ç‹¬ç¿»è¯‘ç»Ÿè®¡: ç¬¬{global_index+1}ä¸ªç‰‡æ®µä½¿ç”¨ç¼“å­˜ï¼Œè·³è¿‡APIè°ƒç”¨")
                            else:
                                # ä½¿ç”¨ç™¾åº¦ç¿»è¯‘API
                                print(f"ğŸŒ å¼€å§‹APIç¿»è¯‘: ç¬¬{global_index+1}ä¸ªç‰‡æ®µ")
                                chinese_text = baidu_translate(japanese_text, max_retries=3)
                                
                                # ä¿å­˜åˆ°ç¼“å­˜
                                _translation_cache[cache_key] = chinese_text
                                print(f"âœ… ç¿»è¯‘å®Œæˆ")
                                print(f"ğŸ“Š å•ç‹¬ç¿»è¯‘ç»Ÿè®¡: ç¬¬{global_index+1}ä¸ªç‰‡æ®µAPIç¿»è¯‘æˆåŠŸ")
                            
                            print(f"ğŸŒ ç¿»è¯‘: {chinese_text}")
                            print(f"ğŸ“Š å½“å‰ç¼“å­˜æ¡ç›®æ•°: {len(_translation_cache)}")
                    else:
                        chinese_text = ""  # ç©ºæ–‡æœ¬å¤„ç†
                    
                    srt_content += f"{global_index+1}\n"
                    srt_content += f"{start_time} --> {end_time}\n"
                    srt_content += f"<font size=\"12\" color=\"#FFD700\">{japanese_text}</font>\n"
                    srt_content += f"<font size=\"16\" color=\"#FFFFFF\">{chinese_text}</font>\n\n"
            else:
                # å¤„ç†ç©ºæ‰¹æ¬¡ï¼ˆåªæœ‰ç©ºæ–‡æœ¬ï¼‰
                for idx, segment in enumerate(batch_segments):
                    global_index = i + idx
                    start_time = format_time(segment['start'])
                    end_time = format_time(segment['end'])
                    japanese_text = segment['text'].strip()
                    
                    srt_content += f"{global_index+1}\n"
                    srt_content += f"{start_time} --> {end_time}\n"
                    srt_content += f"<font size=\"12\" color=\"#FFD700\">{japanese_text}</font>\n"
                    srt_content += f"<font size=\"16\" color=\"#FFFFFF\"></font>\n\n"
            
            # æ›´æ–°è¿›åº¦
            i = batch_end
            
            # å®æ—¶è¿›åº¦æ˜¾ç¤º
            progress_percent = int(i / total_segments * 100)
            progress_bar_length = int(progress_percent / 2)
            progress_bar = "â–ˆ" * progress_bar_length + " " * (50 - progress_bar_length)
            print(f"\rğŸ“Š ç¿»è¯‘è¿›åº¦: [{progress_bar}] {progress_percent}% ({i}/{total_segments})", end="", flush=True)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)
            
            # å®æ—¶ä¿å­˜è¿›åº¦åˆ°ç£ç›˜ï¼ˆæ¯æ‰¹ä¿å­˜ä¸€æ¬¡ï¼‰
            if video_path:
                # æ„å»ºå®Œæ•´çš„è¿›åº¦æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
                progress_data = {
                    'video_path': video_path,
                    'output_path': output_path,
                    'last_translated_index': i,
                    'srt_content': srt_content,
                    'total_segments': total_segments,
                    'progress_percent': progress_percent,
                    'last_save_time': datetime.now().isoformat(),
                    'transcription_result': transcription_result,  # ä¿å­˜å®Œæ•´çš„è¯†åˆ«ç»“æœä»¥ä¾¿æ¢å¤
                    'status': 'translating'
                }
                
                # å°è¯•ä¿å­˜è¿›åº¦ï¼Œå¦‚æœå¤±è´¥åˆ™ç»§ç»­å¤„ç†ï¼ˆä¸ä¸­æ–­æµç¨‹ï¼‰
                save_success = save_progress(video_path, progress_data)
                if not save_success:
                    print(f"âš ï¸ è­¦å‘Šï¼šè¿›åº¦ä¿å­˜å¤±è´¥ï¼Œç»§ç»­å¤„ç†å½“å‰æ‰¹æ¬¡")
        
        # å®Œæˆè¿›åº¦æ˜¾ç¤º
        print(f"\rğŸ“Š ç¿»è¯‘è¿›åº¦: [" + "â–ˆ" * 50 + "] 100% ({total_segments}/{total_segments})")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # ä¸æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼Œä¿æŒæ–­ç‚¹ç»­ä¼ æ–‡ä»¶
        if video_path:
            # æ„å»ºæœ€ç»ˆçš„å®ŒæˆçŠ¶æ€è¿›åº¦æ•°æ®
            final_progress_data = {
                'video_path': video_path,
                'output_path': output_path,
                'last_translated_index': total_segments,
                'srt_content': srt_content,
                'total_segments': total_segments,
                'progress_percent': 100,
                'completed': True,
                'completion_time': datetime.now().isoformat(),
                'subtitle_file': output_path,
                'status': 'completed',
                'transcription_result': transcription_result,  # ä¿å­˜å®Œæ•´çš„è¯†åˆ«ç»“æœ
                'execution_summary': {
                    'total_translated_segments': total_segments,
                    'file_size': len(srt_content),
                    'completion_timestamp': datetime.now().isoformat()
                }
            }
            
            # ç¡®ä¿æœ€ç»ˆè¿›åº¦ä¿å­˜æˆåŠŸ
            final_save_success = save_progress(video_path, final_progress_data)
            if final_save_success:
                print(f"ğŸ’¾ æœ€ç»ˆè¿›åº¦æ–‡ä»¶å·²ä¿å­˜: {get_progress_file_path(video_path)}")
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šæœ€ç»ˆè¿›åº¦ä¿å­˜å¤±è´¥ï¼Œä½†å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ")
        
        print(f"âœ… åŒè¯­å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
        return True
    
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå­—å¹•æ–‡ä»¶å¤±è´¥: {e}")
        # ä¿å­˜é”™è¯¯è¿›åº¦ä»¥ä¾¿æ¢å¤
        if video_path:
            progress_data = {
                'last_translated_index': start_index,
                'srt_content': srt_content,
                'total_segments': total_segments,
                'progress_percent': int(start_index / total_segments * 100) if total_segments > 0 else 0,
                'error': str(e),
                'error_time': datetime.now().isoformat()
            }
            save_progress(video_path, progress_data)
            print(f"ğŸ’¾ é”™è¯¯è¿›åº¦å·²ä¿å­˜ï¼Œå¯æ–­ç‚¹ç»­ä¼ ")
        return False

def format_time(seconds):
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºSRTæ—¶é—´æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = seconds % 60
    milliseconds = int((seconds - int(seconds)) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"



def auto_select_model(video_path, user_model_size='medium'):
    """æ ¹æ®è§†é¢‘æ—¶é•¿è‡ªåŠ¨é€‰æ‹©æ¨¡å‹å¤§å°"""
    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†æ¨¡å‹å¤§å°ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©
    return user_model_size

def main(video_path=None, test_mode=True, model_size='medium', enable_translation=True, output_dir=None, adult_content=False, merge_to_video=False, clean_progress=False):
    """ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºCPUçŠ¶æ€
    cpu_info = check_cpu_availability()
    print(f"ğŸ” ç³»ç»Ÿæ£€æµ‹: {cpu_info}")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè§†é¢‘æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„è§†é¢‘æ–‡ä»¶
    if not video_path:
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv']
        for file in os.listdir('.'):
            if any(file.lower().endswith(ext) for ext in video_extensions):
                video_path = file
                break
        
        if not video_path:
            print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼Œè¯·æŒ‡å®šè§†é¢‘æ–‡ä»¶è·¯å¾„")
            return
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹å¤§å°
    selected_model_size = auto_select_model(video_path, model_size)
    
    # æˆäººå†…å®¹ä¼˜åŒ–æç¤º
    if adult_content:
        print("ğŸ” æˆäººå†…å®¹æ¨¡å¼å·²å¯ç”¨")
        print(f"   - ä½¿ç”¨ä¸“ä¸šæœ¯è¯­è¯å…¸ä¼˜åŒ–ç¿»è¯‘")
        print(f"   - å»ºè®®ä½¿ç”¨ {selected_model_size} æˆ–æ›´é«˜ç²¾åº¦æ¨¡å‹")
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
    print(f"ğŸŒ è¯†åˆ«è¯­è¨€: æ—¥è¯­ â†’ {'ä¸­æ–‡' if enable_translation else 'ä»…è¯†åˆ«'}")
    print(f"ğŸ”¬ æµ‹è¯•æ¨¡å¼: {'å¼€å¯' if test_mode else 'å…³é—­'}")
    print(f"ğŸ”§ ä½¿ç”¨Whisper {selected_model_size}æ¨¡å‹ {'+ ç™¾åº¦ç¿»è¯‘API' if enable_translation else ''}")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ–­ç‚¹ç»­ä¼ æ–‡ä»¶ï¼Œé¿å…é‡å¤è¯†åˆ«
    progress = load_progress(video_path)
    result = None
    
    if progress and 'transcription_result' in progress:
        print("âœ… ä½¿ç”¨å·²ä¿å­˜çš„è¯­éŸ³è¯†åˆ«ç»“æœï¼Œè·³è¿‡è¯†åˆ«é˜¶æ®µ")
        result = progress['transcription_result']
    else:
        # æå–éŸ³é¢‘
        audio_path = os.path.join(temp_dir, "audio.wav")
        if not extract_audio_segment(video_path, audio_path, segment_duration=test_mode):
            return
        
        # ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆCPUæ¨¡å¼ï¼Œæ”¯æŒè¿›åº¦æ˜¾ç¤ºå’Œæ–­ç‚¹ç»­ä¼ ï¼‰
        model = setup_whisper_model(selected_model_size)
        result = transcribe_with_whisper(audio_path, model=model, language='ja', video_path=video_path)
    
    if not result:
        return
    
    # ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆä¸è§†é¢‘æ–‡ä»¶åŒåä¸”åœ¨åŒä¸€ç›®å½•ï¼‰
    subtitle_path = get_same_dir_subtitle_path(video_path, enable_translation)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çŠ¶æ€çš„è¿›åº¦æ–‡ä»¶
    if progress and 'error' in progress:
        print(f"ğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡ä¸­æ–­çš„è¿›åº¦ï¼Œç»§ç»­å¤„ç†...")
        print(f"   é”™è¯¯ä¿¡æ¯: {progress.get('error', 'æœªçŸ¥é”™è¯¯')}")
        print(f"   é”™è¯¯æ—¶é—´: {progress.get('error_time', 'æœªçŸ¥æ—¶é—´')}")
    
    # ä¿å­˜è¯­éŸ³è¯†åˆ«ç»“æœåˆ°è¿›åº¦æ–‡ä»¶
    progress_data = {
        'transcription_result': result,
        'video_path': video_path,
        'model_size': selected_model_size,
        'enable_translation': enable_translation,
        'save_time': datetime.now().isoformat(),
        'transcription_completed': True
    }
    save_progress(video_path, progress_data)
    print(f"ğŸ’¾ è¯­éŸ³è¯†åˆ«è¿›åº¦å·²ä¿å­˜: {get_progress_file_path(video_path)}")
    
    if enable_translation:
        success = generate_bilingual_subtitle_file(result, subtitle_path, video_path, adult_content=adult_content)
    else:
        # ä»…ç”Ÿæˆæ—¥è¯­å­—å¹•
        success = generate_japanese_subtitle_file(result, subtitle_path)
    
    if success:
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœæ‘˜è¦
        segments = result.get('segments', [])
        total_duration = sum(segment['end'] - segment['start'] for segment in segments)
        
        print(f"\nğŸ“Š è¯†åˆ«ç»“æœæ‘˜è¦:")
        print(f"   è¯†åˆ«ç‰‡æ®µæ•°: {len(segments)}")
        print(f"   æ€»è¯†åˆ«æ—¶é•¿: {total_duration:.2f}ç§’")
        print(f"   å­—å¹•æ–‡ä»¶: {subtitle_path}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªè¯†åˆ«ç‰‡æ®µä½œä¸ºç¤ºä¾‹
        print(f"\nğŸ“‹ å‰5ä¸ªç‰‡æ®µç¤ºä¾‹:")
        for i, segment in enumerate(segments[:5]):
            japanese_text = segment['text'].strip()
            if enable_translation:
                chinese_text = baidu_translate(japanese_text)
                print(f"   {i+1}. [{format_time(segment['start'])}]")
                print(f"       æ—¥è¯­: {japanese_text}")
                print(f"       ä¸­æ–‡: {chinese_text}")
                time.sleep(0.2)  # é¿å…è¯·æ±‚è¿‡å¿«
            else:
                print(f"   {i+1}. [{format_time(segment['start'])}]")
                print(f"       æ—¥è¯­: {japanese_text}")
    
    # å­—å¹•åˆå¹¶åˆ°è§†é¢‘
    if merge_to_video and success:
        print("\nğŸ¬ å¼€å§‹å­—å¹•åˆå¹¶åˆ°è§†é¢‘...")
        if check_ffmpeg_installed():
            # ç¡®å®šå­—å¹•è¯­è¨€
            subtitle_language = 'chi' if enable_translation else 'jpn'
            
            # åˆå¹¶å­—å¹•åˆ°è§†é¢‘
            merge_success = merge_subtitle_to_video(
                video_path=video_path,
                subtitle_path=subtitle_path,
                subtitle_language=subtitle_language
            )
            
            if merge_success:
                print("âœ… å­—å¹•å·²æˆåŠŸåµŒå…¥è§†é¢‘æ–‡ä»¶ä¸­")
                print("ğŸ’¡ æ’­æ”¾æ—¶å¯åœ¨æ’­æ”¾å™¨å­—å¹•èœå•ä¸­é€‰æ‹©å†…ç½®å­—å¹•")
            else:
                print("âš ï¸ å­—å¹•åˆå¹¶å¤±è´¥ï¼Œä¿ç•™ç‹¬ç«‹çš„å­—å¹•æ–‡ä»¶")
        else:
            print("âŒ FFmpegæœªå®‰è£…ï¼Œæ— æ³•åˆå¹¶å­—å¹•åˆ°è§†é¢‘")
            print("ğŸ’¡ è¯·å®‰è£…FFmpegæˆ–ä½¿ç”¨å¤–éƒ¨æ’­æ”¾å™¨åŠ è½½å­—å¹•æ–‡ä»¶")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        # æ£€æŸ¥audio_pathå˜é‡æ˜¯å¦å­˜åœ¨ä¸”æ–‡ä»¶å­˜åœ¨
        if 'audio_path' in locals() and os.path.exists(audio_path):
            os.remove(audio_path)
            print("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        else:
            print("ğŸ“ æ— ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶éœ€è¦æ¸…ç†")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # è¿›åº¦æ–‡ä»¶ç®¡ç†
    progress_file = get_progress_file_path(video_path)
    if clean_progress:
        # æ¸…ç†è¿›åº¦æ–‡ä»¶
        if os.path.exists(progress_file):
            try:
                os.remove(progress_file)
                print("ğŸ§¹ è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•æ¸…ç†è¿›åº¦æ–‡ä»¶: {e}")
    else:
        # é»˜è®¤ä¿ç•™è¿›åº¦æ–‡ä»¶ä»¥ä¾¿æ–­ç‚¹ç»­ä¼ 
        if os.path.exists(progress_file):
            print(f"ğŸ“ è¿›åº¦æ–‡ä»¶å·²ä¿ç•™: {progress_file}")
            print("ğŸ’¡ å¦‚éœ€æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --clean-progress å‚æ•°æˆ–æ‰‹åŠ¨åˆ é™¤")

def generate_japanese_subtitle_file(transcription_result, output_path):
    """ç”Ÿæˆä»…æ—¥è¯­å­—å¹•æ–‡ä»¶"""
    print("ğŸ“ ç”Ÿæˆæ—¥è¯­å­—å¹•æ–‡ä»¶...")
    
    try:
        # ç”ŸæˆSRTæ ¼å¼å­—å¹•
        srt_content = ""
        segments = transcription_result.get('segments', [])
        
        for i, segment in enumerate(segments, 1):
            start_time = format_time(segment['start'])
            end_time = format_time(segment['end'])
            japanese_text = segment['text'].strip()
            
            if japanese_text:  # åªå¤„ç†éç©ºæ–‡æœ¬
                srt_content += f"{i}\n"
                srt_content += f"{start_time} --> {end_time}\n"
                srt_content += f"{japanese_text}\n\n"
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        print(f"âœ… æ—¥è¯­å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå­—å¹•æ–‡ä»¶å¤±è´¥: {e}")
        return False

def merge_subtitle_to_video(video_path, subtitle_path, output_path=None, subtitle_language='chi'):
    """å°†å­—å¹•åˆå¹¶åˆ°è§†é¢‘æ–‡ä»¶ä¸­"""
    print(f"ğŸ¬ å¼€å§‹åˆå¹¶å­—å¹•åˆ°è§†é¢‘...")
    
    if not output_path:
        video_name = Path(video_path).stem
        output_path = f"{video_name}_with_subtitle.mp4"
    
    try:
        # æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
        if not check_ffmpeg_installed():
            print("âŒ FFmpegæœªå®‰è£…æˆ–ä¸å¯ç”¨ï¼Œæ— æ³•åˆå¹¶å­—å¹•")
            print("ğŸ’¡ è¯·å®‰è£…FFmpegï¼šhttps://ffmpeg.org/download.html")
            return False
        
        # æ„å»ºFFmpegå‘½ä»¤
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-i', subtitle_path,
            '-c', 'copy',  # å¤åˆ¶è§†é¢‘å’ŒéŸ³é¢‘æµ
            '-c:s', 'mov_text',  # å­—å¹•ç¼–ç æ ¼å¼
            '-metadata:s:s:0', f'language={subtitle_language}',
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]
        
        print(f"   ğŸ“¥ è¾“å…¥è§†é¢‘: {video_path}")
        print(f"   ğŸ“„ è¾“å…¥å­—å¹•: {subtitle_path}")
        print(f"   ğŸ“¤ è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"   ğŸ”§ å­—å¹•è¯­è¨€: {subtitle_language}")
        
        # æ‰§è¡Œåˆå¹¶
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… å­—å¹•åˆå¹¶æˆåŠŸ: {output_path}")
            print(f"ğŸ’¡ æ’­æ”¾æ—¶å¯åœ¨æ’­æ”¾å™¨ä¸­é€‰æ‹©å­—å¹•è½¨é“")
            return True
        else:
            print(f"âŒ å­—å¹•åˆå¹¶å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

def check_ffmpeg_installed():
    """æ£€æŸ¥FFmpegæ˜¯å¦å·²å®‰è£…"""
    try:
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False

def get_progress_file_path(video_path):
    """è·å–è¿›åº¦æ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åœ¨tempç›®å½•ä¸‹ï¼‰"""
    video_name = Path(video_path).stem
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    return os.path.join(temp_dir, f"{video_name}_progress.json")

def save_progress(video_path, progress_data):
    """ä¿å­˜è¿›åº¦åˆ°æ–‡ä»¶ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰"""
    progress_file = get_progress_file_path(video_path)
    try:
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(progress_file), exist_ok=True)
        
        # æ·»åŠ ä¿å­˜æ—¶é—´æˆ³
        progress_data['last_save_timestamp'] = datetime.now().isoformat()
        
        # åˆ†å—å†™å…¥ä»¥é¿å…å¤§æ–‡ä»¶æ“ä½œé—®é¢˜
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
        if os.path.exists(progress_file):
            file_size = os.path.getsize(progress_file)
            if file_size > 0:
                return True
            else:
                print(f"âš ï¸ è¿›åº¦æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼šæ–‡ä»¶ä¸ºç©º")
                return False
        return False
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSONç¼–ç é”™è¯¯ï¼Œæ— æ³•ä¿å­˜è¿›åº¦: {e}")
        return False
    except IOError as e:
        print(f"âš ï¸ IOé”™è¯¯ï¼Œæ— æ³•ä¿å­˜è¿›åº¦: {e}")
        return False
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜è¿›åº¦æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return False

def load_progress(video_path):
    """ä»æ–‡ä»¶åŠ è½½è¿›åº¦ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰"""
    progress_file = get_progress_file_path(video_path)
    if os.path.exists(progress_file):
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if os.path.getsize(progress_file) == 0:
                print(f"âš ï¸ è¿›åº¦æ–‡ä»¶ä¸ºç©º: {progress_file}")
                return None
                
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress = json.load(f)
                
            # éªŒè¯è¿›åº¦æ•°æ®çš„å®Œæ•´æ€§
            if not isinstance(progress, dict):
                print("âš ï¸ è¿›åº¦æ•°æ®æ ¼å¼é”™è¯¯ï¼šä¸æ˜¯æœ‰æ•ˆçš„å­—å…¸")
                return None
                
            # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨ï¼ˆæ ¹æ®ä¸åŒé˜¶æ®µçš„éœ€æ±‚ï¼‰
            if 'status' in progress:
                status = progress['status']
                if status == 'transcribing' and 'transcription_progress' not in progress:
                    print("âš ï¸ è½¬å½•é˜¶æ®µè¿›åº¦æ•°æ®ä¸å®Œæ•´")
                elif status == 'completed' and 'transcription_result' not in progress:
                    print("âš ï¸ å®Œæˆé˜¶æ®µè¿›åº¦æ•°æ®ä¸å®Œæ•´")
                    
            return progress
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æé”™è¯¯ï¼Œæ— æ³•åŠ è½½è¿›åº¦æ–‡ä»¶: {e}")
            # å°è¯•æ¸…ç†æŸåçš„è¿›åº¦æ–‡ä»¶
            try:
                os.remove(progress_file)
                print(f"ğŸ§¹ å·²æ¸…ç†æŸåçš„è¿›åº¦æ–‡ä»¶: {progress_file}")
            except:
                pass
        except IOError as e:
            print(f"âš ï¸ IOé”™è¯¯ï¼Œæ— æ³•è¯»å–è¿›åº¦æ–‡ä»¶: {e}")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è¿›åº¦æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    return None

def cleanup_progress(video_path):
    """æ¸…ç†è¿›åº¦æ–‡ä»¶"""
    progress_file = get_progress_file_path(video_path)
    if os.path.exists(progress_file):
        try:
            os.remove(progress_file)
            print("ğŸ§¹ è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ¸…ç†è¿›åº¦æ–‡ä»¶: {e}")

def get_same_dir_subtitle_path(video_path, enable_translation=True):
    """è·å–ä¸è§†é¢‘æ–‡ä»¶åŒç›®å½•çš„å­—å¹•æ–‡ä»¶è·¯å¾„"""
    video_dir = Path(video_path).parent
    video_name = Path(video_path).stem
    
    if enable_translation:
        subtitle_name = f"{video_name}.srt"  # ä¸è§†é¢‘æ–‡ä»¶åŒå
    else:
        subtitle_name = f"{video_name}_japanese.srt"
    
    return str(video_dir / subtitle_name)



if __name__ == "__main__":
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='è§†é¢‘å­—å¹•è¯†åˆ«ä¸ç¿»è¯‘å·¥å…·')
    parser.add_argument('video_path', nargs='?', help='è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆä»…å¤„ç†å‰10%%å†…å®¹ï¼‰')
    parser.add_argument('--model', default='medium', choices=['tiny', 'base', 'small', 'medium', 'large'],
                        help='Whisperæ¨¡å‹å¤§å°ï¼ˆé»˜è®¤ï¼šmediumï¼‰')
    parser.add_argument('--no-translate', action='store_true', help='ä»…è¯†åˆ«ä¸ç¿»è¯‘')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--adult', action='store_true', help='æˆäººå†…å®¹æ¨¡å¼ï¼ˆä¼˜åŒ–ä¸“ä¸šæœ¯è¯­ç¿»è¯‘ï¼‰')
    parser.add_argument('--merge', action='store_true', help='å°†å­—å¹•åˆå¹¶åˆ°è§†é¢‘æ–‡ä»¶ä¸­ï¼ˆéœ€è¦FFmpegï¼‰')
    parser.add_argument('--clean-progress', action='store_true', help='æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼ˆé»˜è®¤ä¿ç•™ï¼‰')
    
    args = parser.parse_args()
    
    # æ¨¡å‹æ¨èï¼šæˆäººå†…å®¹å»ºè®®ä½¿ç”¨mediumæˆ–large
    if args.adult and args.model in ['tiny', 'base', 'small']:
        print("âš ï¸  æˆäººå†…å®¹å»ºè®®ä½¿ç”¨mediumæˆ–largeæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„è¯†åˆ«ç²¾åº¦")
    
    # æ£€æŸ¥FFmpegæ˜¯å¦å·²å®‰è£…ï¼ˆå¦‚æœå¯ç”¨äº†åˆå¹¶åŠŸèƒ½ï¼‰
    if args.merge and not check_ffmpeg_installed():
        print("âš ï¸  FFmpegæœªå®‰è£…ï¼Œå­—å¹•åˆå¹¶åŠŸèƒ½å°†ä¸å¯ç”¨")
        print("ğŸ’¡  è¯·å®‰è£…FFmpegï¼šhttps://ffmpeg.org/download.html")
        print("ğŸ’¡  æˆ–è€…ä½¿ç”¨å¤–éƒ¨æ’­æ”¾å™¨åŠ è½½ç‹¬ç«‹çš„å­—å¹•æ–‡ä»¶")
    
    try:
        main(
            video_path=args.video_path,
            test_mode=args.test,
            model_size=args.model,
            enable_translation=not args.no_translate,
            output_dir=args.output_dir,
            adult_content=args.adult,
            merge_to_video=args.merge,
            clean_progress=args.clean_progress
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç¨‹åºå·²è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¨‹åºç»“æŸæ—¶ä¿å­˜ç¿»è¯‘ç¼“å­˜
        save_translation_cache()
