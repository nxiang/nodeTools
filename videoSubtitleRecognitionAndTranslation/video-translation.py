#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç¿»è¯‘å·¥å…·
ä¼ å…¥è§†é¢‘åœ°å€ï¼Œå…ˆè°ƒç”¨whisper-transcription.pyå¾—åˆ°SRTå­—å¹•ï¼Œå†è°ƒç”¨srt-translation.pyå¾—åˆ°åŒè¯­å­—å¹•
"""

import os
import sys
import time
import subprocess
from pathlib import Path
from typing import Dict, Optional


class TimeTracker:
    """è€—æ—¶è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.last_checkpoint = self.start_time
        self.checkpoints = {}
    
    def checkpoint(self, stage_name: str):
        """è®°å½•æ£€æŸ¥ç‚¹è€—æ—¶"""
        current_time = time.time()
        stage_duration = current_time - self.last_checkpoint
        total_duration = current_time - self.start_time
        
        self.checkpoints[stage_name] = {
            'stage_duration': stage_duration,
            'total_duration': total_duration
        }
        
        print(f"[è€—æ—¶] [{stage_name}] é˜¶æ®µè€—æ—¶: {stage_duration:.2f}s, ç´¯è®¡è€—æ—¶: {total_duration:.2f}s")
        
        # æ›´æ–°æœ€åæ£€æŸ¥ç‚¹æ—¶é—´
        self.last_checkpoint = current_time
        
        return stage_duration, total_duration
    
    def print_summary(self):
        """æ‰“å°è€—æ—¶æ€»ç»“"""
        total_duration = time.time() - self.start_time
        print(f"\n[ç»Ÿè®¡] æ€»è€—æ—¶ç»Ÿè®¡:")
        print(f"   æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"\n[è¯¦æƒ…] å„é˜¶æ®µè€—æ—¶è¯¦æƒ…:")
        for stage, times in self.checkpoints.items():
            print(f"   {stage}: {times['stage_duration']:.2f}ç§’")


class VideoTranslator:
    """è§†é¢‘ç¿»è¯‘å™¨"""
    
    def __init__(self, whisper_model: str = "base", device: str = "cpu", 
                 source_lang: str = "ja", target_lang: str = "zh-CN"):
        """
        åˆå§‹åŒ–è§†é¢‘ç¿»è¯‘å™¨
        
        Args:
            whisper_model: Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large, large-v1, lage-v2, large-v3, larrge-v3-turbo, turbo)
            device: è¿è¡Œè®¾å¤‡ (cpu, cuda)
            source_lang: æºè¯­è¨€ä»£ç  (ja=æ—¥è¯­, en=è‹±è¯­ç­‰)
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç  (zh-CN=ç®€ä½“ä¸­æ–‡)
        """
        self.whisper_model = whisper_model
        self.device = device
        self.source_lang = source_lang
        self.target_lang = target_lang
        
        # è®¾ç½®å·¥ä½œç›®å½•
        self.workspace_dir = Path("temp")
        self.workspace_dir.mkdir(exist_ok=True)
        
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
        self.script_dir = Path(__file__).parent
        self.whisper_script = self.script_dir / "whisper-transcription.py"
        self.srt_translation_script = self.script_dir / "srt-translation.py"
        
        # éªŒè¯è„šæœ¬æ–‡ä»¶å­˜åœ¨
        if not self.whisper_script.exists():
            raise FileNotFoundError(f"Whisperè½¬å½•è„šæœ¬ä¸å­˜åœ¨: {self.whisper_script}")
        if not self.srt_translation_script.exists():
            raise FileNotFoundError(f"SRTç¿»è¯‘è„šæœ¬ä¸å­˜åœ¨: {self.srt_translation_script}")
    
    def _check_existing_transcription(self, video_path: str) -> Optional[Path]:
        """
        æ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å½•æ–‡ä»¶å¯ä»¥å¤ç”¨
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¦‚æœæ‰¾åˆ°å¯å¤ç”¨çš„è½¬å½•æ–‡ä»¶ï¼Œè¿”å›SRTæ–‡ä»¶è·¯å¾„ï¼Œå¦åˆ™è¿”å›None
        """
        video_name = Path(video_path).stem
        temp_dir = Path("temp")
        
        if not temp_dir.exists():
            return None
        
        print(f"[å¤ç”¨æ£€æŸ¥] æ£€æŸ¥å·²æœ‰è½¬å½•æ–‡ä»¶...")
        print(f"   è§†é¢‘åç§°: {video_name}")
        print(f"   æ¨¡å‹: {self.whisper_model}")
        
        # æŸ¥æ‰¾åŒ¹é…çš„è½¬å½•æ–‡ä»¶
        txt_files = []
        for subdir in temp_dir.iterdir():
            if subdir.is_dir() and video_name in subdir.name and self.whisper_model in subdir.name:
                txt_file = subdir / "transcription.txt"
                if txt_file.exists():
                    txt_files.append(txt_file)
                    print(f"   âœ“ æ‰¾åˆ°è½¬å½•æ–‡ä»¶: {txt_file}")
                    break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å°±é€€å‡º
        
        if txt_files:
            txt_file = txt_files[0]
            
            # æ£€æŸ¥è½¬å½•æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆæœ‰è¶³å¤Ÿçš„å†…å®¹ï¼‰
            try:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…è½¬å½•å†…å®¹ï¼ˆæ’é™¤æ–‡ä»¶å¤´ä¿¡æ¯ï¼‰
                lines_with_content = [line for line in content.split('\n') 
                                    if line.strip() and '=' not in line 
                                    and not line.startswith('è§†é¢‘:') 
                                    and not line.startswith('æ¨¡å‹:') 
                                    and line.startswith('[') and ']' in line]
                
                if len(lines_with_content) > 0:
                    print(f"   âœ“ è½¬å½•æ–‡ä»¶åŒ…å« {len(lines_with_content)} ä¸ªæœ‰æ•ˆå­—å¹•å—")
                    
                    # å°†txtæ–‡ä»¶è½¬æ¢ä¸ºSRTæ ¼å¼
                    srt_file = self._convert_txt_to_srt(txt_file)
                    if srt_file:
                        print(f"   âœ“ æˆåŠŸè½¬æ¢ä¸ºSRTæ ¼å¼: {srt_file.name}")
                        return srt_file
                    else:
                        print(f"   âœ— SRTè½¬æ¢å¤±è´¥")
                        return None
                else:
                    print(f"   âœ— è½¬å½•æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
                    return None
                    
            except Exception as e:
                print(f"   âœ— æ£€æŸ¥è½¬å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                return None
        
        print(f"   âœ— æœªæ‰¾åˆ°å¯å¤ç”¨çš„è½¬å½•æ–‡ä»¶")
        return None
    
    def run_whisper_transcription(self, video_path: str, output_dir: Optional[str] = None, enable_memory_optimization: bool = False, max_chunk_duration: int = 180) -> Optional[str]:
        """
        è¿è¡ŒWhisperè½¬å½•ï¼Œç”ŸæˆSRTå­—å¹•æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            enable_memory_optimization: æ˜¯å¦å¯ç”¨å†…å­˜ä¼˜åŒ–
            max_chunk_duration: æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            SRTæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯å¤ç”¨çš„è½¬å½•æ–‡ä»¶
            existing_srt = self._check_existing_transcription(video_path)
            if existing_srt:
                print(f"[å¤ç”¨] âœ“ å¤ç”¨å·²æœ‰è½¬å½•æ–‡ä»¶ï¼Œè·³è¿‡è½¬å½•è¿‡ç¨‹")
                
                # å°†SRTæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                if output_dir:
                    output_path = Path(output_dir)
                    output_path.mkdir(exist_ok=True)
                    video_name = Path(video_path).stem
                    final_srt_file = output_path / f"{video_name}.srt"
                    existing_srt.rename(final_srt_file)
                    print(f"[å¤ç”¨] è½¬å½•å®Œæˆ: {final_srt_file.name}")
                    return str(final_srt_file)
                else:
                    print(f"[å¤ç”¨] è½¬å½•å®Œæˆ: {existing_srt.name}")
                    return str(existing_srt)
            
            # å¦‚æœæ²¡æœ‰å¯å¤ç”¨çš„æ–‡ä»¶ï¼Œæ‰§è¡Œè½¬å½•
            print(f"[Whisper] å¼€å§‹è½¬å½•...")
            print(f"   è§†é¢‘æ–‡ä»¶: {Path(video_path).name}")
            print(f"   æ¨¡å‹: {self.whisper_model}")
            print(f"   è¯­è¨€: {self.source_lang}")
            print(f"   åˆ†æ®µæ—¶é•¿: {max_chunk_duration}ç§’")
            
            # æ„å»ºå‘½ä»¤è¡Œå‚æ•° - åªä¼ é€’whisper-transcription.pyæ”¯æŒçš„å‚æ•°
            cmd = [
                sys.executable, 'whisper-transcription.py',
                video_path,
                '--model', self.whisper_model,
                '--language', self.source_lang,
                '--segment-duration', str(max_chunk_duration)
            ]
            
            # æ‰§è¡Œè½¬å½•ï¼Œå®æ—¶æ˜¾ç¤ºè¾“å‡º
            result = subprocess.run(cmd, capture_output=False, text=True, encoding='utf-8', cwd=self.script_dir)
            
            if result.returncode == 0:
                # whisper-transcription.pyç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„æ ¼å¼: temp/{video_name}_{hash}_{model}/transcription.txt
                video_name = Path(video_path).stem
                
                # æŸ¥æ‰¾tempç›®å½•ä¸‹çš„è½¬å½•æ–‡ä»¶
                temp_dir = Path("temp")
                if not temp_dir.exists():
                    print(f"[Whisper] tempç›®å½•ä¸å­˜åœ¨: {temp_dir}")
                    return None
                
                # æŸ¥æ‰¾åŒ¹é…çš„è½¬å½•æ–‡ä»¶
                # ç”±äºæ–‡ä»¶åå¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚æ–¹æ‹¬å·ï¼‰ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„æœç´¢æ–¹å¼
                txt_files = []
                for subdir in temp_dir.iterdir():
                    if subdir.is_dir() and video_name in subdir.name and self.whisper_model in subdir.name:
                        txt_file = subdir / "transcription.txt"
                        if txt_file.exists():
                            txt_files.append(txt_file)
                            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å°±é€€å‡º
                
                if txt_files:
                    txt_file = txt_files[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
                    
                    # å°†txtæ–‡ä»¶è½¬æ¢ä¸ºSRTæ ¼å¼
                    srt_file = self._convert_txt_to_srt(txt_file)
                    if srt_file:
                        # å°†SRTæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                        if output_dir:
                            output_path = Path(output_dir)
                            output_path.mkdir(exist_ok=True)
                            final_srt_file = output_path / f"{video_name}.srt"
                            srt_file.rename(final_srt_file)
                            print(f"[Whisper] è½¬å½•å®Œæˆ: {final_srt_file.name}")
                            return str(final_srt_file)
                        else:
                            print(f"[Whisper] è½¬å½•å®Œæˆ: {srt_file.name}")
                            return str(srt_file)
                    else:
                        print(f"[Whisper] SRTæ–‡ä»¶è½¬æ¢å¤±è´¥")
                        return None
                else:
                    print(f"[Whisper] è½¬å½•æ–‡ä»¶æœªæ‰¾åˆ°")
                    return None
            else:
                # ç”±äºcapture_output=Falseï¼Œstderrä¸ä¼šè¢«æ•è·ï¼Œæ˜¾ç¤ºé€šç”¨é”™è¯¯ä¿¡æ¯
                print(f"[Whisper] è½¬å½•è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œä½†å¯èƒ½å·²æœ‰éƒ¨åˆ†è½¬å½•å†…å®¹")
                print(f"[Whisper] è¿”å›ç : {result.returncode}")
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆäº†éƒ¨åˆ†è½¬å½•æ–‡ä»¶
                video_name = Path(video_path).stem
                temp_dir = Path("temp")
                
                # ç”±äºæ–‡ä»¶åå¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚æ–¹æ‹¬å·ï¼‰ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„æœç´¢æ–¹å¼
                # å…ˆæ‰¾åˆ°æ‰€æœ‰åŒ…å«è§†é¢‘åç§°çš„ç›®å½•ï¼Œç„¶ååœ¨è¿™äº›ç›®å½•ä¸­æŸ¥æ‰¾transcription.txt
                txt_files = []
                for subdir in temp_dir.iterdir():
                    if subdir.is_dir() and video_name in subdir.name:
                        txt_file = subdir / "transcription.txt"
                        if txt_file.exists():
                            txt_files.append(txt_file)
                            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å°±é€€å‡º
                
                if txt_files:
                    print(f"[Whisper] å‘ç°éƒ¨åˆ†è½¬å½•æ–‡ä»¶ï¼Œå¯èƒ½ä»æœ‰å¯ç”¨å†…å®¹")
                    txt_file = txt_files[0]
                    srt_file = self._convert_txt_to_srt(txt_file)
                    if srt_file:
                        # é‡å‘½åä¸ºpartial.srtä»¥è¡¨ç¤ºéƒ¨åˆ†è½¬å½•
                        partial_srt = srt_file.with_name(f"{video_name}_partial.srt")
                        srt_file.rename(partial_srt)
                        print(f"[Whisper] éƒ¨åˆ†è½¬å½•è½¬æ¢å®Œæˆ: {partial_srt.name}")
                        
                        # å°†SRTæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                        if output_dir:
                            output_path = Path(output_dir)
                            output_path.mkdir(exist_ok=True)
                            final_srt_file = output_path / f"{video_name}_partial.srt"
                            partial_srt.rename(final_srt_file)
                            print(f"[Whisper] å·²ç”Ÿæˆéƒ¨åˆ†è½¬å½•æ–‡ä»¶: {final_srt_file.name}")
                        else:
                            print(f"[Whisper] å·²ç”Ÿæˆéƒ¨åˆ†è½¬å½•æ–‡ä»¶: {partial_srt.name}")
                            return str(partial_srt)
                    else:
                        print("[Whisper] éƒ¨åˆ†è½¬å½•è½¬æ¢å¤±è´¥")
                        return None
                else:
                    print(f"[Whisper] è½¬å½•å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                    return None
                
        except Exception as e:
            print(f"âŒ è¿è¡ŒWhisperè½¬å½•æ—¶å‡ºé”™: {e}")
            return None
    
    def _convert_txt_to_srt(self, txt_file: Path) -> Optional[Path]:
        """
        å°†whisper-transcription.pyç”Ÿæˆçš„txtæ–‡ä»¶è½¬æ¢ä¸ºSRTæ ¼å¼
        
        Args:
            txt_file: è¾“å…¥çš„txtæ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„SRTæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # è¯»å–txtæ–‡ä»¶å†…å®¹
            with open(txt_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # è·³è¿‡æ–‡ä»¶å¤´ä¿¡æ¯ï¼ˆå‰å‡ è¡Œï¼‰
            content_lines = []
            for line in lines:
                if line.strip() and '=' not in line and not line.startswith('è§†é¢‘:') and not line.startswith('æ¨¡å‹:'):
                    content_lines.append(line.strip())
            
            # è§£ææ—¶é—´æˆ³å’Œæ–‡æœ¬
            srt_entries = []
            entry_index = 1
            
            for line in content_lines:
                if line.startswith('[') and ']' in line:
                    # è§£ææ—¶é—´æˆ³è¡Œï¼Œå¦‚: [00:01:23 - 00:01:45] æ–‡æœ¬å†…å®¹
                    time_part, text_part = line.split(']', 1)
                    time_part = time_part[1:]  # å»æ‰å¼€å¤´çš„[
                    
                    if ' - ' in time_part:
                        start_time, end_time = time_part.split(' - ', 1)
                        
                        # å°†æ—¶é—´æ ¼å¼è½¬æ¢ä¸ºSRTæ ¼å¼ï¼ˆHH:MM:SS,mmmï¼‰
                        def convert_time_format(time_str):
                            # æ ¼å¼: HH:MM:SS -> HH:MM:SS,000
                            parts = time_str.split(':')
                            if len(parts) == 3:
                                return f"{parts[0]}:{parts[1]}:{parts[2]},000"
                            return time_str
                        
                        srt_start = convert_time_format(start_time.strip())
                        srt_end = convert_time_format(end_time.strip())
                        
                        # åˆ›å»ºSRTæ¡ç›®
                        srt_entry = f"{entry_index}\n{srt_start} --> {srt_end}\n{text_part.strip()}\n"
                        srt_entries.append(srt_entry)
                        entry_index += 1
            
            # ç”ŸæˆSRTæ–‡ä»¶
            srt_file = txt_file.with_suffix('.srt')
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(srt_entries))
            
            return srt_file
            
        except Exception as e:
            print(f"âŒ è½¬æ¢txtåˆ°SRTæ—¶å‡ºé”™: {e}")
            return None
    
    def run_srt_translation(self, srt_path: str) -> bool:
        """
        è¿è¡ŒSRTç¿»è¯‘ï¼Œç”ŸæˆåŒè¯­å­—å¹•
        
        Args:
            srt_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # æ„å»ºSRTç¿»è¯‘å‘½ä»¤
        # ä¸æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼Œè®©srt-translation.pyè‡ªåŠ¨å¤„ç†ï¼š
        # è¾“å‡ºæ–‡ä»¶åæ”¹ä¸ºåŸæ–‡ä»¶åï¼ŒåŸæ–‡åæ”¹ä¸º.back.srt
        command = [
            sys.executable, str(self.srt_translation_script),
            srt_path,
            "--source-lang", self.source_lang,
            "--target-lang", self.target_lang
        ]
        
        print(f"[ç¿»è¯‘] å¼€å§‹SRTç¿»è¯‘...")
        print(f"   è¾“å…¥æ–‡ä»¶: {Path(srt_path).name}")
        print(f"   æºè¯­è¨€: {self.source_lang}")
        print(f"   ç›®æ ‡è¯­è¨€: {self.target_lang}")
        print(f"   æ–‡ä»¶åå¤„ç†: è¾“å‡ºæ–‡ä»¶å°†ä¿æŒåŸæ–‡ä»¶åï¼ŒåŸæ–‡ä»¶å°†å¤‡ä»½ä¸º.back.srt")
        
        try:
            # è¿è¡Œç¿»è¯‘å‘½ä»¤ï¼Œå®æ—¶æ˜¾ç¤ºè¾“å‡º
            result = subprocess.run(command, capture_output=False, text=True, cwd=self.script_dir)
            
            if result.returncode == 0:
                print(f"[æˆåŠŸ] SRTç¿»è¯‘å®Œæˆ")
                return True
            else:
                print(f"[å¤±è´¥] SRTç¿»è¯‘å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿è¡ŒSRTç¿»è¯‘æ—¶å‡ºé”™: {e}")
            return False
    
    def translate_video(self, video_path: str, output_dir: Optional[str] = None, enable_memory_optimization: bool = False, max_chunk_duration: int = 180) -> Dict:
        """
        å®Œæ•´çš„è§†é¢‘ç¿»è¯‘æµç¨‹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            enable_memory_optimization: æ˜¯å¦å¯ç”¨å†…å­˜ä¼˜åŒ–
            max_chunk_duration: æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            ç¿»è¯‘ç»“æœä¿¡æ¯
        """
        # åˆå§‹åŒ–è€—æ—¶è·Ÿè¸ªå™¨
        time_tracker = TimeTracker()
        
        # éªŒè¯è§†é¢‘æ–‡ä»¶å­˜åœ¨
        video_file = Path(video_path)
        if not video_file.exists():
            print(f"[å¤±è´¥] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return {"error": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨", "success": False}
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = self.workspace_dir
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        time_tracker.checkpoint("åˆå§‹åŒ–")
        
        result = {
            "video_path": video_path,
            "output_dir": str(output_path),
            "success": False,
            "stages": {}
        }
        
        # é˜¶æ®µ1: Whisperè½¬å½•
        print("=" * 60)
        print(f"[å¼€å§‹] å¼€å§‹è§†é¢‘ç¿»è¯‘æµç¨‹")
        print(f"   è§†é¢‘: {video_file.name}")
        print(f"   è¾“å‡ºç›®å½•: {output_path}")
        if enable_memory_optimization:
            print(f"   å†…å­˜ä¼˜åŒ–: å·²å¯ç”¨ï¼Œåˆ†å—æ—¶é•¿: {max_chunk_duration}ç§’")
        print("=" * 60)
        
        srt_file = self.run_whisper_transcription(video_path, output_dir, enable_memory_optimization, max_chunk_duration)
        time_tracker.checkpoint("Whisperè½¬å½•")
        
        if not srt_file:
            result["error"] = "Whisperè½¬å½•å¤±è´¥"
            time_tracker.print_summary()
            return result
        
        result["original_srt"] = srt_file
        result["stages"]["transcription"] = True
        
        # é˜¶æ®µ2: SRTç¿»è¯‘
        print("\n" + "=" * 60)
        print("[å¼€å§‹] å¼€å§‹å­—å¹•ç¿»è¯‘é˜¶æ®µ")
        print("=" * 60)
        
        # ä¸æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼Œè®©srt-translation.pyè‡ªåŠ¨å¤„ç†ï¼š
        # è¾“å‡ºæ–‡ä»¶åæ”¹ä¸ºåŸæ–‡ä»¶åï¼ŒåŸæ–‡åæ”¹ä¸º.back.srt
        translation_success = self.run_srt_translation(srt_file)
        time_tracker.checkpoint("SRTç¿»è¯‘")
        
        if not translation_success:
            result["error"] = "SRTç¿»è¯‘å¤±è´¥"
            time_tracker.print_summary()
            return result
        
        # ç¿»è¯‘åçš„æ–‡ä»¶å°†ä¿æŒåŸæ–‡ä»¶åï¼ŒåŸæ–‡ä»¶å¤‡ä»½ä¸º.back.srt
        result["translated_srt"] = srt_file
        result["backup_srt"] = str(Path(srt_file).parent / f"{Path(srt_file).stem}.back.srt")
        result["stages"]["translation"] = True
        result["success"] = True
        
        # é˜¶æ®µ3: æ¸…ç†å’Œæ€»ç»“
        print("\n" + "=" * 60)
        print("[å®Œæˆ] è§†é¢‘ç¿»è¯‘å®Œæˆ!")
        print("=" * 60)
        
        # æ˜¾ç¤ºç»“æœæ–‡ä»¶
        print(f"[æ–‡ä»¶] ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   åŒè¯­SRT: {Path(srt_file).name} (åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º.back.srt)")
        print(f"   å¤‡ä»½æ–‡ä»¶: {Path(srt_file).stem}.back.srt")
        
        # æ‰“å°è€—æ—¶æ€»ç»“
        time_tracker.print_summary()
        result["processing_time"] = time.time() - time_tracker.start_time
        
        return result


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è§†é¢‘ç¿»è¯‘å·¥å…·")
    parser.add_argument("video_path", help="è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", "-m", default="base", 
                       choices=["tiny", "base", "small", "medium", "large", "large-v1", "large-v2", "large-v3", "large-v3-turbo", "turbo"],
                       help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: base)")
    parser.add_argument("--device", default="cpu", choices=["cpu", "cuda"],
                       help="è¿è¡Œè®¾å¤‡ (é»˜è®¤: cpu)")
    parser.add_argument("--source-lang", default="ja", 
                       help="æºè¯­è¨€ä»£ç  (é»˜è®¤: ja=æ—¥è¯­)")
    parser.add_argument("--target-lang", default="zh-CN", 
                       help="ç›®æ ‡è¯­è¨€ä»£ç  (é»˜è®¤: zh-CN=ç®€ä½“ä¸­æ–‡)")
    parser.add_argument("--output-dir", help="è¾“å‡ºç›®å½• (é»˜è®¤: temp)")
    
    # å†…å­˜ä¼˜åŒ–å‚æ•°
    parser.add_argument("--enable-memory-optimization", action="store_true",
                       help="å¯ç”¨å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼Œæ”¯æŒlarge-v2æ¨¡å‹åœ¨16GBå†…å­˜æœºå™¨ä¸Šè¿è¡Œ")
    parser.add_argument("--max-chunk-duration", type=int, default=180,
                       help="å†…å­˜ä¼˜åŒ–æ¨¡å¼ä¸‹çš„æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ (é»˜è®¤: 180)")
    
    args = parser.parse_args()
    
    # éªŒè¯è§†é¢‘æ–‡ä»¶å­˜åœ¨
    if not Path(args.video_path).exists():
        print(f"[å¤±è´¥] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        return 1
    
    # åˆå§‹åŒ–è§†é¢‘ç¿»è¯‘å™¨
    try:
        translator = VideoTranslator(
            whisper_model=args.model,
            device=args.device,
            source_lang=args.source_lang,
            target_lang=args.target_lang
        )
    except Exception as e:
        print(f"[å¤±è´¥] åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1
    
    # æ‰§è¡Œè§†é¢‘ç¿»è¯‘
    result = translator.translate_video(
        video_path=args.video_path,
        output_dir=args.output_dir,
        enable_memory_optimization=args.enable_memory_optimization,
        max_chunk_duration=args.max_chunk_duration
    )
    
    if result["success"]:
        print(f"\n[æˆåŠŸ] è§†é¢‘ç¿»è¯‘æˆåŠŸå®Œæˆ!")
        return 0
    else:
        print(f"\n[å¤±è´¥] è§†é¢‘ç¿»è¯‘å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return 1


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    if len(sys.argv) == 1:
        print("ğŸ¬ è§†é¢‘ç¿»è¯‘å·¥å…·")
        print("=" * 50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python video-translation.py <è§†é¢‘æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]")
        print("")
        print("é€‰é¡¹:")
        print("  --model MODEL        Whisperæ¨¡å‹ (tiny, base, small, medium, large, large-v1, large-v2, large-v3, large-v3-turbo, turbo)")
        print("  --device DEVICE      è¿è¡Œè®¾å¤‡ (cpu, cuda)")
        print("  --source-lang LANG   æºè¯­è¨€ä»£ç  (ja, zh, enç­‰)")
        print("  --target-lang LANG   ç›®æ ‡è¯­è¨€ä»£ç  (zh-CN, enç­‰)")
        print("  --output-dir DIR     è¾“å‡ºç›®å½•")
        print("")
        print("ç¤ºä¾‹:")
        print("  python video-translation.py my_video.mp4 --model base --source-lang ja --target-lang zh-CN")
        print("  python video-translation.py video.avi --model large-v4 --device cuda")
        print("")
        
        # æµ‹è¯•ç¤ºä¾‹
        test_video = input("è¾“å…¥æµ‹è¯•è§†é¢‘è·¯å¾„ (æˆ–æŒ‰å›è½¦è·³è¿‡): ").strip()
        if test_video and Path(test_video).exists():
            print(f"\n[å¼€å§‹] å¼€å§‹æµ‹è¯•å¤„ç†: {test_video}")
            
            translator = VideoTranslator()
            result = translator.translate_video(video_path=test_video)
        else:
            print("âŒ æœªæä¾›æœ‰æ•ˆçš„æµ‹è¯•è§†é¢‘è·¯å¾„")
    else:
        # æ­£å¸¸å‘½ä»¤è¡Œæ‰§è¡Œ
        exit(main())
