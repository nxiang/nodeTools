#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç¿»è¯‘å·¥å…·
ä¼ å…¥è§†é¢‘åœ°å€ï¼Œå…ˆè°ƒç”¨whisper-transcription.pyå¾—åˆ°SRTå­—å¹•ï¼Œå†è°ƒç”¨srt-translation.pyå¾—åˆ°åŒè¯­å­—å¹•
"""

import os
import sys
import time
import subprocess
import hashlib
import json  # æ·»åŠ jsonå¯¼å…¥
from pathlib import Path
from typing import Dict, Optional
import send2trash  # æ–°å¢å¯¼å…¥ï¼Œç”¨äºå°†æ–‡ä»¶ç§»åŠ¨åˆ°å›æ”¶ç«™


class TimeTracker:
    """è€—æ—¶è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.last_checkpoint = self.start_time
        self.checkpoints = {}
    
    def checkpoint(self, stage_name: str):
        """è®°å½•æ£€æŸ¥ç‚¹è€—æ—¶"""
        current_time = time.time()
        stage_duration = current_time - self.last_checkpoint
        total_duration = current_time - self.start_time
        
        self.checkpoints[stage_name] = {
            'stage_duration': stage_duration,
            'total_duration': total_duration
        }
        
        print(f"[è€—æ—¶] [{stage_name}] é˜¶æ®µè€—æ—¶: {stage_duration:.2f}s, ç´¯è®¡è€—æ—¶: {total_duration:.2f}s")
        
        # æ›´æ–°æœ€åæ£€æŸ¥ç‚¹æ—¶é—´
        self.last_checkpoint = current_time
        
        return stage_duration, total_duration
    
    def print_summary(self):
        """æ‰“å°è€—æ—¶æ€»ç»“"""
        total_duration = time.time() - self.start_time
        print(f"\n[ç»Ÿè®¡] æ€»è€—æ—¶ç»Ÿè®¡:")
        print(f"   æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"\n[è¯¦æƒ…] å„é˜¶æ®µè€—æ—¶è¯¦æƒ…:")
        for stage, times in self.checkpoints.items():
            print(f"   {stage}: {times['stage_duration']:.2f}ç§’")


class VideoTranslator:
    """è§†é¢‘ç¿»è¯‘å™¨"""
    
    def __init__(self, whisper_model: str = "base", device: str = "cpu", 
                 source_lang: str = "ja", target_lang: str = "zh-CN", 
                 use_vad: bool = False):
        """
        åˆå§‹åŒ–è§†é¢‘ç¿»è¯‘å™¨
        
        Args:
            whisper_model: Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large, large-v1, lage-v2, large-v3, large-v3-turbo, turbo)
            device: è¿è¡Œè®¾å¤‡ (cpu, cuda)
            source_lang: æºè¯­è¨€ä»£ç  (ja=æ—¥è¯­, en=è‹±è¯­ç­‰)
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç  (zh-CN=ç®€ä½“ä¸­æ–‡)
            use_vad: æ˜¯å¦ä½¿ç”¨VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰è½¬å½•
        """
        self.whisper_model = whisper_model
        self.device = device
        self.source_lang = source_lang
        self.target_lang = target_lang
        self.use_vad = use_vad
        
        # è®¾ç½®å·¥ä½œç›®å½•
        self.workspace_dir = Path("temp")
        self.workspace_dir.mkdir(exist_ok=True)
        
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
        self.script_dir = Path(__file__).parent
        # æ ¹æ®use_vadé€‰æ‹©è½¬å½•è„šæœ¬
        if self.use_vad:
            self.whisper_script = self.script_dir / "whisper-transcription.vad.py"
        else:
            self.whisper_script = self.script_dir / "whisper-transcription.py"
        self.srt_translation_script = self.script_dir / "srt-translation.py"
        
        # éªŒè¯è„šæœ¬æ–‡ä»¶å­˜åœ¨
        if not self.whisper_script.exists():
            raise FileNotFoundError(f"Whisperè½¬å½•è„šæœ¬ä¸å­˜åœ¨: {self.whisper_script}")
        if not self.srt_translation_script.exists():
            raise FileNotFoundError(f"SRTç¿»è¯‘è„šæœ¬ä¸å­˜åœ¨: {self.srt_translation_script}")
    
    def _check_existing_transcription(self, video_path: str) -> Dict:
        """
        æ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å½•æ–‡ä»¶æˆ–è½¬å½•çŠ¶æ€
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¿”å›åŒ…å«çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
        """
        video_name = Path(video_path).stem
        temp_dir = Path("temp")
        
        if not temp_dir.exists():
            return {"should_continue": False, "reason": "tempç›®å½•ä¸å­˜åœ¨"}
        
        print(f"[çŠ¶æ€æ£€æŸ¥] æ£€æŸ¥å·²æœ‰è½¬å½•çŠ¶æ€...")
        print(f"   è§†é¢‘åç§°: {video_name}")
        print(f"   æ¨¡å‹: {self.whisper_model}")
        
        # æŸ¥æ‰¾åŒ¹é…çš„çŠ¶æ€æ–‡ä»¶
        state_files = []
        for subdir in temp_dir.iterdir():
            if subdir.is_dir() and video_name in subdir.name and self.whisper_model in subdir.name:
                state_file = subdir / "transcription_state.json"
                if state_file.exists():
                    state_files.append(state_file)
                    print(f"   âœ“ æ‰¾åˆ°è½¬å½•çŠ¶æ€æ–‡ä»¶: {state_file}")
        
        if not state_files:
            return {"should_continue": False, "reason": "æœªæ‰¾åˆ°è½¬å½•çŠ¶æ€æ–‡ä»¶"}
        
        # ä½¿ç”¨æœ€æ–°çš„çŠ¶æ€æ–‡ä»¶
        state_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        state_file = state_files[0]
        
        try:
            # è¯»å–çŠ¶æ€æ–‡ä»¶
            with open(state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            processed_segments = state.get("processed_segments", 0)
            total_segments = state.get("total_segments", 0)
            segments = state.get("segments", [])
            
            print(f"   âœ“ è½¬å½•è¿›åº¦: {processed_segments}/{total_segments} ä¸ªç‰‡æ®µ")
            print(f"   âœ“ å·²è½¬å½•æœ‰æ•ˆç‰‡æ®µ: {len(segments)} ä¸ª")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæˆ
            if processed_segments >= total_segments:
                print(f"   âœ“ æ‰€æœ‰ç‰‡æ®µå·²å¤„ç†å®Œæˆ")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆçš„è½¬å½•æ–‡æœ¬æ–‡ä»¶
                transcription_txt = state_file.parent / "transcription.txt"
                if transcription_txt.exists():
                    print(f"   âœ“ æ‰¾åˆ°å®Œæ•´è½¬å½•æ–‡ä»¶: {transcription_txt}")
                    return {
                        "completed": True,
                        "reason": "è½¬å½•å·²å®Œæˆ",
                        "transcription_file": transcription_txt,
                        "state_file": state_file
                    }
                else:
                    print(f"   â„¹ï¸ è½¬å½•å·²æ ‡è®°å®Œæˆä½†æœªç”Ÿæˆtranscription.txtæ–‡ä»¶")
                    return {
                        "completed": False,
                        "reason": "è½¬å½•çŠ¶æ€å¼‚å¸¸",
                        "state_file": state_file
                    }
            else:
                print(f"   â„¹ï¸ å‘ç°æœªå®Œæˆçš„è½¬å½•å·¥ä½œ")
                print(f"   â„¹ï¸ å°†ç»§ç»­ä»ç¬¬ {processed_segments + 1} ä¸ªç‰‡æ®µå¼€å§‹")
                return {
                    "should_continue": True,
                    "reason": "ç»§ç»­æœªå®Œæˆçš„è½¬å½•",
                    "current_segment": processed_segments,
                    "total_segments": total_segments,
                    "state_file": state_file
                }
                
        except Exception as e:
            print(f"   âœ— å¤„ç†çŠ¶æ€æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {"should_continue": False, "reason": f"çŠ¶æ€æ–‡ä»¶é”™è¯¯: {str(e)}"}
    
    def _convert_txt_to_srt(self, txt_file: Path) -> Optional[Path]:
        """
        å°†whisper-transcription.pyç”Ÿæˆçš„txtæ–‡ä»¶è½¬æ¢ä¸ºSRTæ ¼å¼
        
        Args:
            txt_file: è¾“å…¥çš„txtæ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„SRTæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # è¯»å–txtæ–‡ä»¶å†…å®¹
            with open(txt_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content.strip():
                print(f"   âœ— è½¬å½•æ–‡ä»¶å†…å®¹ä¸ºç©º")
                return None
            
            # è§£ææ–‡ä»¶ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
            # 1. å¸¦æœ‰æ—¶é—´æˆ³çš„è¡Œï¼š[00:01:23 - 00:01:45] æ–‡æœ¬å†…å®¹
            # 2. ç›´æ¥æ˜¯åˆ†æ®µæ–‡æœ¬
            
            lines = content.split('\n')
            srt_entries = []
            entry_index = 1
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # è·³è¿‡æ–‡ä»¶å¤´ä¿¡æ¯è¡Œ
                if any(line.startswith(prefix) for prefix in ['è§†é¢‘:', 'æ¨¡å‹:', 'è¯­è¨€:', 'éŸ³é¢‘é¢„å¤„ç†:', 'è½¬å½•æ—¶é—´:', 'éŸ³é¢‘æ—¶é•¿:', 'åŸå§‹ç‰‡æ®µæ•°:', 'è¿‡æ»¤åç‰‡æ®µæ•°:', 'å»é‡åç‰‡æ®µæ•°:', '=']):
                    continue
                
                # å°è¯•è§£ææ—¶é—´æˆ³è¡Œ
                if line.startswith('[') and ']' in line:
                    try:
                        # è§£ææ—¶é—´æˆ³è¡Œï¼Œå¦‚: [00:01:23 - 00:01:45] æ–‡æœ¬å†…å®¹
                        time_part, text_part = line.split(']', 1)
                        time_part = time_part[1:]  # å»æ‰å¼€å¤´çš„[
                        
                        if ' - ' in time_part:
                            start_time, end_time = time_part.split(' - ', 1)
                            
                            # å°†æ—¶é—´æ ¼å¼è½¬æ¢ä¸ºSRTæ ¼å¼ï¼ˆHH:MM:SS,mmmï¼‰
                            def convert_time_format(time_str):
                                time_str = time_str.strip()
                                # å¦‚æœå·²ç»æ˜¯SRTæ ¼å¼ï¼ˆæœ‰é€—å·ï¼‰ï¼Œç›´æ¥è¿”å›
                                if ',' in time_str:
                                    return time_str
                                # å¦åˆ™æ·»åŠ æ¯«ç§’éƒ¨åˆ†
                                # å¤„ç†å¯èƒ½çš„æ¯«ç§’éƒ¨åˆ†ï¼ˆå¦‚00:01:23.456ï¼‰
                                if '.' in time_str:
                                    parts = time_str.split('.')
                                    time_part = parts[0]
                                    millis = parts[1][:3].ljust(3, '0')
                                    return f"{time_part},{millis}"
                                # æ²¡æœ‰æ¯«ç§’çš„æƒ…å†µ
                                return f"{time_str},000"
                            
                            srt_start = convert_time_format(start_time.strip())
                            srt_end = convert_time_format(end_time.strip())
                            
                            # è·å–æ–‡æœ¬å†…å®¹
                            cleaned_text = text_part.strip()
                            
                            # ç§»é™¤å¼€å¤´çš„[å¼±]æ ‡è®°
                            if cleaned_text.startswith("[å¼±]"):
                                cleaned_text = cleaned_text[3:].strip()
                            
                            # åˆ›å»ºSRTæ¡ç›®
                            if cleaned_text:  # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
                                srt_entry = f"{entry_index}\n{srt_start} --> {srt_end}\n{cleaned_text}\n"
                                srt_entries.append(srt_entry)
                                entry_index += 1
                                
                    except Exception as e:
                        print(f"   è­¦å‘Š: è§£æè¡Œå¤±è´¥ '{line[:50]}...': {e}")
                        continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³æ ¼å¼ï¼Œå°è¯•å…¶ä»–æ ¼å¼
            if not srt_entries:
                # å°è¯•ç›´æ¥ä½¿ç”¨æ‰€æœ‰éç©ºè¡Œä½œä¸ºå­—å¹•
                for i, line in enumerate(lines, 1):
                    line = line.strip()
                    if line and not any(line.startswith(prefix) for prefix in ['è§†é¢‘:', 'æ¨¡å‹:', 'è¯­è¨€:', 'éŸ³é¢‘é¢„å¤„ç†:', 'è½¬å½•æ—¶é—´:', 'éŸ³é¢‘æ—¶é•¿:']):
                        # ä¸ºæ¯è¡Œåˆ›å»ºç®€å•çš„æ—¶é—´æˆ³ï¼ˆæ¯è¡Œ1ç§’ï¼‰
                        start_seconds = i - 1
                        end_seconds = i
                        
                        def seconds_to_srt(seconds):
                            hours = int(seconds // 3600)
                            minutes = int((seconds % 3600) // 60)
                            secs = int(seconds % 60)
                            millis = int((seconds - int(seconds)) * 1000)
                            return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
                        
                        srt_start = seconds_to_srt(start_seconds)
                        srt_end = seconds_to_srt(end_seconds)
                        
                        srt_entry = f"{i}\n{srt_start} --> {srt_end}\n{line}\n"
                        srt_entries.append(srt_entry)
            
            # ç”ŸæˆSRTæ–‡ä»¶
            if srt_entries:
                srt_file = txt_file.with_suffix('.srt')
                with open(srt_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(srt_entries))
                
                print(f"   âœ“ æˆåŠŸè½¬æ¢ {len(srt_entries)} ä¸ªå­—å¹•å—")
                return srt_file
            else:
                print(f"   âœ— æ²¡æœ‰æ‰¾åˆ°å¯è½¬æ¢çš„å­—å¹•å†…å®¹")
                return None
                
        except Exception as e:
            print(f"âŒ è½¬æ¢txtåˆ°SRTæ—¶å‡ºé”™: {e}")
            return None
    
    def run_whisper_transcription(self, video_path: str, output_dir: Optional[str] = None, 
                                  enable_memory_optimization: bool = False, max_chunk_duration: int = 180, 
                                  use_vad: bool = False, test_percentage: int = 0) -> Optional[str]:
        """
        è¿è¡ŒWhisperè½¬å½•ï¼Œç”ŸæˆSRTå­—å¹•æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            enable_memory_optimization: æ˜¯å¦å¯ç”¨å†…å­˜ä¼˜åŒ–
            max_chunk_duration: æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            SRTæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # é¦–å…ˆæ£€æŸ¥è½¬å½•çŠ¶æ€
            status = self._check_existing_transcription(video_path)
            
            if status.get("completed"):
                print(f"[è½¬å½•] âœ“ è½¬å½•å·²å®Œæˆï¼Œå¤ç”¨ç°æœ‰è½¬å½•æ–‡ä»¶")
                transcription_file = Path(status["transcription_file"])
                
                # å°†è½¬å½•æ–‡ä»¶è½¬æ¢ä¸ºSRT
                srt_file = self._convert_txt_to_srt(transcription_file)
                if srt_file:
                    # ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                    if output_dir:
                        output_path = Path(output_dir)
                        output_path.mkdir(exist_ok=True)
                        video_name = Path(video_path).stem
                        final_srt_file = output_path / f"{video_name}.srt"
                        
                        if final_srt_file.exists():
                            final_srt_file.unlink()
                        srt_file.rename(final_srt_file)
                        print(f"[è½¬å½•]   è½¬å½•å®Œæˆ: {final_srt_file.name}")
                        return str(final_srt_file)
                    else:
                        print(f"[è½¬å½•]   è½¬å½•å®Œæˆ: {srt_file.name}")
                        return str(srt_file)
                else:
                    print(f"[è½¬å½•] âœ— è½¬å½•æ–‡ä»¶è½¬æ¢å¤±è´¥ï¼Œå°†é‡æ–°è½¬å½•")
            
            # æ‰§è¡Œè½¬å½•ï¼ˆæ— è®ºæ˜¯å¦å‘ç°æœªå®Œæˆçš„å·¥ä½œï¼Œéƒ½è¿è¡Œè½¬å½•è„šæœ¬ï¼Œå®ƒä¼šè‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­ï¼‰
            print(f"[è½¬å½•] å¼€å§‹è½¬å½•...")
            print(f"   è§†é¢‘æ–‡ä»¶: {Path(video_path).name}")
            print(f"   æ¨¡å‹: {self.whisper_model}")
            print(f"   è¯­è¨€: {self.source_lang}")
            print(f"   åˆ†æ®µæ—¶é•¿: {max_chunk_duration}ç§’")
            print(f"   è½¬å½•è„šæœ¬: {'whisper-transcription.vad.py (VADæ¨¡å¼)' if use_vad else 'whisper-transcription.py (æ ‡å‡†æ¨¡å¼)'}")
            
            # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
            if self.use_vad:
                cmd = [
                    sys.executable, 'whisper-transcription.vad.py',
                    video_path,
                    '--model', self.whisper_model,
                    '--language', self.source_lang
                ]
                if test_percentage > 0:
                    cmd.extend(['--test', str(test_percentage)])
            else:
                cmd = [
                    sys.executable, 'whisper-transcription.py',
                    video_path,
                    '--model', self.whisper_model,
                    '--language', self.source_lang,
                    '--segment-duration', str(max_chunk_duration)
                ]
                if test_percentage > 0:
                    cmd.extend(['--test', str(test_percentage)])
            
            # æ‰§è¡Œè½¬å½•
            print(f"[è½¬å½•] è¿è¡Œè½¬å½•å‘½ä»¤...")
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', cwd=self.script_dir)
            
            print(f"[è½¬å½•] è½¬å½•å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if result.returncode != 0:
                print(f"[è½¬å½•] âœ— è½¬å½•è„šæœ¬è¿”å›é”™è¯¯ä»£ç : {result.returncode}")
                print(f"[è½¬å½•] æ ‡å‡†è¾“å‡º: {result.stdout[:500]}...")
                print(f"[è½¬å½•] é”™è¯¯è¾“å‡º: {result.stderr[:500]}...")
                
                # æ£€æŸ¥è¿”å›ç æ˜¯å¦ä¸ºå†…å­˜è®¿é—®å†²çªï¼ˆå¸¸è§äºWindowsï¼‰
                if result.returncode == 3221225620:
                    print(f"[è½¬å½•] âœ— æ£€æµ‹åˆ°å†…å­˜è®¿é—®å†²çªï¼Œå¯èƒ½æ˜¯å†…å­˜ä¸è¶³æˆ–æ¨¡å‹å¤ªå¤§")
                    print(f"[è½¬å½•] âœ— å»ºè®®: ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼Œæˆ–å¢åŠ ç³»ç»Ÿå†…å­˜")
                
                # å³ä½¿å¤±è´¥ï¼Œä¹Ÿå°è¯•æŸ¥æ‰¾æ˜¯å¦ç”Ÿæˆäº†éƒ¨åˆ†ç»“æœ
                print(f"[è½¬å½•] â„¹ï¸ å°è¯•æŸ¥æ‰¾å·²ç”Ÿæˆçš„éƒ¨åˆ†è½¬å½•æ–‡ä»¶...")
            
            # è½¬å½•å®Œæˆåï¼ŒæŸ¥æ‰¾ç»“æœ
            video_name = Path(video_path).stem
            
            # æ¸…ç†æ–‡ä»¶å
            safe_video_name = "".join(c if c.isalnum() or c in "_-" else "_" for c in video_name)
            safe_video_name = safe_video_name[:50]
            
            # æŸ¥æ‰¾è½¬å½•ç»“æœæ–‡ä»¶
            transcription_txt = None
            video_hash = hashlib.md5(str(video_path).encode()).hexdigest()[:8]
            
            # å°è¯•å¤šç§ç›®å½•æ ¼å¼
            possible_dirs = [
                Path("temp") / f"{safe_video_name}_{video_hash}_{self.whisper_model}",
                Path("temp") / f"{safe_video_name}_{self.whisper_model}",
                Path("temp") / f"{safe_video_name}__{self.whisper_model}",
            ]
            
            for temp_dir in possible_dirs:
                if temp_dir.exists():
                    candidate_txt = temp_dir / "transcription.txt"
                    if candidate_txt.exists():
                        transcription_txt = candidate_txt
                        print(f"[è½¬å½•] æ‰¾åˆ°è½¬å½•æ–‡ä»¶: {transcription_txt}")
                        break
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨é€šé…ç¬¦æœç´¢
            if transcription_txt is None:
                temp_dir = Path("temp")
                if temp_dir.exists():
                    pattern = f"*{safe_video_name}*{self.whisper_model}*"
                    for model_dir in temp_dir.glob(pattern):
                        if model_dir.is_dir():
                            candidate_txt = model_dir / "transcription.txt"
                            if candidate_txt.exists():
                                transcription_txt = candidate_txt
                                print(f"[è½¬å½•] æ‰¾åˆ°è½¬å½•æ–‡ä»¶ï¼ˆé€šé…ç¬¦ï¼‰: {transcription_txt}")
                                break
            
            if transcription_txt is None:
                print(f"[è½¬å½•] âœ— æœªæ‰¾åˆ°è½¬å½•æ–‡ä»¶")
                
                # æ£€æŸ¥æ˜¯å¦è½¬å½•è¢«ä¸­æ–­
                # æŸ¥æ‰¾çŠ¶æ€æ–‡ä»¶æ£€æŸ¥è¿›åº¦
                state_file = None
                for temp_dir in possible_dirs:
                    if temp_dir.exists():
                        candidate_state = temp_dir / "transcription_state.json"
                        if candidate_state.exists():
                            state_file = candidate_state
                            break
                
                if state_file:
                    try:
                        with open(state_file, 'r', encoding='utf-8') as f:
                            state = json.load(f)
                        
                        processed = state.get("processed_segments", 0)
                        total = state.get("total_segments", 0)
                        
                        if processed < total:
                            print(f"[è½¬å½•] â„¹ï¸ è½¬å½•è¢«ä¸­æ–­ï¼Œè¿›åº¦: {processed}/{total}")
                            print(f"[è½¬å½•] â„¹ï¸ è¯·é‡æ–°è¿è¡Œå‘½ä»¤ä»¥ç»§ç»­è½¬å½•")
                        elif processed >= total:
                            print(f"[è½¬å½•] â„¹ï¸ è½¬å½•å·²å®Œæˆä½†æœªç”Ÿæˆtranscription.txtæ–‡ä»¶")
                    except:
                        pass
                
                return None
            
            # å°†è½¬å½•æ–‡ä»¶è½¬æ¢ä¸ºSRT
            srt_file = self._convert_txt_to_srt(transcription_txt)
            if not srt_file:
                print(f"[è½¬å½•] âœ— è½¬å½•æ–‡ä»¶è½¬æ¢å¤±è´¥")
                return None
            
            # ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
            if output_dir:
                output_path = Path(output_dir)
                output_path.mkdir(exist_ok=True)
                final_srt_file = output_path / f"{video_name}.srt"
                
                if final_srt_file.exists():
                    final_srt_file.unlink()
                
                srt_file.rename(final_srt_file)
                print(f"[è½¬å½•] SRTæ–‡ä»¶å·²ä¿å­˜: {final_srt_file.name}")
                return str(final_srt_file)
            else:
                print(f"[è½¬å½•] SRTæ–‡ä»¶å·²ä¿å­˜: {srt_file.name}")
                return str(srt_file)
                
        except Exception as e:
            print(f"âŒ è¿è¡ŒWhisperè½¬å½•æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_srt_translation(self, srt_path: str) -> bool:
        """
        è¿è¡ŒSRTç¿»è¯‘ï¼Œç”ŸæˆåŒè¯­å­—å¹•
        
        Args:
            srt_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # ç¡®ä¿SRTæ–‡ä»¶è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
        srt_abs_path = Path(srt_path).absolute()
        
        # æ£€æŸ¥SRTæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not srt_abs_path.exists():
            print(f"âŒ SRTæ–‡ä»¶ä¸å­˜åœ¨: {srt_abs_path}")
            return False
        
        # æ„å»ºSRTç¿»è¯‘å‘½ä»¤
        # ä¸æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼Œè®©srt-translation.pyè‡ªåŠ¨å¤„ç†ï¼š
        # è¾“å‡ºæ–‡ä»¶åæ”¹ä¸ºåŸæ–‡ä»¶åï¼ŒåŸæ–‡åæ”¹ä¸º.back.srt
        command = [
            sys.executable, str(self.srt_translation_script),
            str(srt_abs_path),
            "--source-lang", self.source_lang,
            "--target-lang", self.target_lang
        ]
        
        print(f"[ç¿»è¯‘] å¼€å§‹SRTç¿»è¯‘...")
        print(f"   è¾“å…¥æ–‡ä»¶: {srt_abs_path.name}")
        print(f"   æ–‡ä»¶è·¯å¾„: {srt_abs_path}")
        print(f"   æºè¯­è¨€: {self.source_lang}")
        print(f"   ç›®æ ‡è¯­è¨€: {self.target_lang}")
        print(f"   æ–‡ä»¶åå¤„ç†: è¾“å‡ºæ–‡ä»¶å°†ä¿æŒåŸæ–‡ä»¶åï¼ŒåŸæ–‡ä»¶å°†å¤‡ä»½ä¸º.back.srt")
        
        try:
            # è¿è¡Œç¿»è¯‘å‘½ä»¤ï¼Œå®æ—¶æ˜¾ç¤ºè¾“å‡º
            result = subprocess.run(command, capture_output=False, text=True, cwd=self.script_dir)
            
            if result.returncode == 0:
                print(f"[æˆåŠŸ] SRTç¿»è¯‘å®Œæˆ")
                return True
            else:
                print(f"[å¤±è´¥] SRTç¿»è¯‘å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿è¡ŒSRTç¿»è¯‘æ—¶å‡ºé”™: {e}")
            return False
    
    def translate_video(self, video_path: str, output_dir: Optional[str] = None, 
                        enable_memory_optimization: bool = False, max_chunk_duration: int = 180, 
                        use_vad: bool = False, test_percentage: int = 0) -> Dict:
        """
        å®Œæ•´çš„è§†é¢‘ç¿»è¯‘æµç¨‹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            enable_memory_optimization: æ˜¯å¦å¯ç”¨å†…å­˜ä¼˜åŒ–
            max_chunk_duration: æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            ç¿»è¯‘ç»“æœä¿¡æ¯
        """
        # åˆå§‹åŒ–è€—æ—¶è·Ÿè¸ªå™¨
        time_tracker = TimeTracker()
        
        # éªŒè¯è§†é¢‘æ–‡ä»¶å­˜åœ¨
        video_file = Path(video_path)
        if not video_file.exists():
            print(f"[å¤±è´¥] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return {"error": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨", "success": False}
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = self.workspace_dir
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        time_tracker.checkpoint("åˆå§‹åŒ–")
        
        result = {
            "video_path": video_path,
            "output_dir": str(output_path),
            "success": False,
            "stages": {}
        }
        
        # é˜¶æ®µ1: Whisperè½¬å½•
        print("=" * 60)
        print(f"[å¼€å§‹] å¼€å§‹è§†é¢‘ç¿»è¯‘æµç¨‹")
        print(f"   è§†é¢‘: {video_file.name}")
        print(f"   è¾“å‡ºç›®å½•: {output_path}")
        if use_vad:
            print(f"   è½¬å½•æ¨¡å¼: VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ¨¡å¼")
        else:
            print(f"   è½¬å½•æ¨¡å¼: æ ‡å‡†æ¨¡å¼")
        if test_percentage > 0:
            print(f"   æµ‹è¯•æ¨¡å¼: ä»…å¤„ç†å‰ {test_percentage}%")
        print("=" * 60)
        
        # æ£€æŸ¥è½¬å½•çŠ¶æ€
        status = self._check_existing_transcription(video_path)
        if status.get("should_continue"):
            print(f"[è½¬å½•] â„¹ï¸ å‘ç°æœªå®Œæˆçš„è½¬å½•å·¥ä½œ")
            print(f"[è½¬å½•] â„¹ï¸ å°†ç»§ç»­ä»ç¬¬ {status['current_segment'] + 1}/{status['total_segments']} ä¸ªç‰‡æ®µå¼€å§‹")
        
        srt_file = self.run_whisper_transcription(video_path, output_dir, 
                                                  enable_memory_optimization, max_chunk_duration, 
                                                  use_vad, test_percentage)
        time_tracker.checkpoint("Whisperè½¬å½•")
        
        if not srt_file:
            result["error"] = "Whisperè½¬å½•å¤±è´¥"
            time_tracker.print_summary()
            return result
        
        result["original_srt"] = srt_file
        result["stages"]["transcription"] = True
        
        # é˜¶æ®µ2: SRTç¿»è¯‘
        print("\n" + "=" * 60)
        print("[å¼€å§‹] å¼€å§‹å­—å¹•ç¿»è¯‘é˜¶æ®µ")
        print("=" * 60)
        
        # ä¸æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼Œè®©srt-translation.pyè‡ªåŠ¨å¤„ç†ï¼š
        # è¾“å‡ºæ–‡ä»¶åæ”¹ä¸ºåŸæ–‡ä»¶åï¼ŒåŸæ–‡åæ”¹ä¸º.back.srt
        translation_success = self.run_srt_translation(srt_file)
        time_tracker.checkpoint("SRTç¿»è¯‘")
        
        if not translation_success:
            result["error"] = "SRTç¿»è¯‘å¤±è´¥"
            time_tracker.print_summary()
            return result
        
        # ç¿»è¯‘åçš„æ–‡ä»¶å°†ä¿æŒåŸæ–‡ä»¶åï¼ŒåŸæ–‡ä»¶å¤‡ä»½ä¸º.back.srt
        result["translated_srt"] = srt_file
        result["backup_srt"] = str(Path(srt_file).parent / f"{Path(srt_file).stem}.back.srt")
        result["stages"]["translation"] = True
        result["success"] = True
        
        # é˜¶æ®µ3: æ¸…ç†å’Œæ€»ç»“
        print("\n" + "=" * 60)
        print("[å®Œæˆ] è§†é¢‘ç¿»è¯‘å®Œæˆ!")
        print("=" * 60)
        
        # æ˜¾ç¤ºç»“æœæ–‡ä»¶
        print(f"[æ–‡ä»¶] ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   åŒè¯­SRT: {Path(srt_file).name} (åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º.back.srt)")
        print(f"   å¤‡ä»½æ–‡ä»¶: {Path(srt_file).stem}.back.srt")
        
        # æ‰“å°è€—æ—¶æ€»ç»“
        time_tracker.print_summary()
        result["processing_time"] = time.time() - time_tracker.start_time
        
        return result


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è§†é¢‘ç¿»è¯‘å·¥å…·")
    parser.add_argument("video_path", help="è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", "-m", default="base", 
                       choices=["tiny", "base", "small", "medium", "large", "large-v1", "large-v2", "large-v3", "large-v3-turbo", "turbo"],
                       help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: base)")
    parser.add_argument("--device", default="cpu", choices=["cpu", "cuda"],
                       help="è¿è¡Œè®¾å¤‡ (é»˜è®¤: cpu)")
    parser.add_argument("--source-lang", default="ja", 
                       help="æºè¯­è¨€ä»£ç  (é»˜è®¤: ja=æ—¥è¯­)")
    parser.add_argument("--target-lang", default="zh-CN", 
                       help="ç›®æ ‡è¯­è¨€ä»£ç  (é»˜è®¤: zh-CN=ç®€ä½“ä¸­æ–‡)")
    parser.add_argument("--output-dir", help="è¾“å‡ºç›®å½• (é»˜è®¤: temp)")
    
    # å†…å­˜ä¼˜åŒ–å‚æ•°
    parser.add_argument("--enable-memory-optimization", action="store_true",
                       help="å¯ç”¨å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼Œæ”¯æŒlarge-v2æ¨¡å‹åœ¨16GBå†…å­˜æœºå™¨ä¸Šè¿è¡Œ")
    parser.add_argument("--max-chunk-duration", type=int, default=180,
                       help="å†…å­˜ä¼˜åŒ–æ¨¡å¼ä¸‹çš„æœ€å¤§åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ (é»˜è®¤: 180)")
    
    # VADå‚æ•°
    parser.add_argument("--vad", action="store_true",
                       help="ä½¿ç”¨VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ¨¡å¼è¿›è¡Œè½¬å½•ï¼Œä½¿ç”¨whisper-transcription.vad.pyè„šæœ¬")
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument("--test", type=int, default=0,
                       help="æµ‹è¯•æ¨¡å¼ï¼šä»…è½¬å½•å‰ç™¾åˆ†ä¹‹Nçš„éŸ³é¢‘ (é»˜è®¤: 0=ç¦ç”¨ï¼Œ10=è½¬å½•å‰10%)")
    
    args = parser.parse_args()
    
    # éªŒè¯è§†é¢‘æ–‡ä»¶å­˜åœ¨
    if not Path(args.video_path).exists():
        print(f"[å¤±è´¥] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        return 1
    
    # åˆå§‹åŒ–è§†é¢‘ç¿»è¯‘å™¨
    try:
        translator = VideoTranslator(
            whisper_model=args.model,
            device=args.device,
            source_lang=args.source_lang,
            target_lang=args.target_lang,
            use_vad=args.vad
        )
    except Exception as e:
        print(f"[å¤±è´¥] åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1
    
    # æ‰§è¡Œè§†é¢‘ç¿»è¯‘
    result = translator.translate_video(
        video_path=args.video_path,
        output_dir=args.output_dir,
        enable_memory_optimization=args.enable_memory_optimization,
        max_chunk_duration=args.max_chunk_duration,
        use_vad=args.vad,
        test_percentage=args.test
    )
    
    if result["success"]:
        print(f"\n[æˆåŠŸ] è§†é¢‘ç¿»è¯‘æˆåŠŸå®Œæˆ!")
        return 0
    else:
        print(f"\n[å¤±è´¥] è§†é¢‘ç¿»è¯‘å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return 1


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    if len(sys.argv) == 1:
        print("ğŸ¬ è§†é¢‘ç¿»è¯‘å·¥å…·")
        print("=" * 50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python video-translation.py <è§†é¢‘æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]")
        print("")
        print("é€‰é¡¹:")
        print("  --model MODEL        Whisperæ¨¡å‹ (tiny, base, small, medium, large, large-v1, large-v2, large-v3, large-v3-turbo, turbo)")
        print("  --device DEVICE      è¿è¡Œè®¾å¤‡ (cpu, cuda)")
        print("  --source-lang LANG   æºè¯­è¨€ä»£ç  (ja, zh, enç­‰)")
        print("  --target-lang LANG   ç›®æ ‡è¯­è¨€ä»£ç  (zh-CN, enç­‰)")
        print("  --output-dir DIR     è¾“å‡ºç›®å½•")
        print("")
        print("ç¤ºä¾‹:")
        print("  python video-translation.py my_video.mp4 --model base --source-lang ja --target-lang zh-CN")
        print("  python video-translation.py video.avi --model large-v4 --device cuda")
        print("")
        
        # æµ‹è¯•ç¤ºä¾‹
        test_video = input("è¾“å…¥æµ‹è¯•è§†é¢‘è·¯å¾„ (æˆ–æŒ‰å›è½¦è·³è¿‡): ").strip()
        if test_video and Path(test_video).exists():
            print(f"\n[å¼€å§‹] å¼€å§‹æµ‹è¯•å¤„ç†: {test_video}")
            
            translator = VideoTranslator()
            result = translator.translate_video(video_path=test_video)
        else:
            print("âŒ æœªæä¾›æœ‰æ•ˆçš„æµ‹è¯•è§†é¢‘è·¯å¾„")
    else:
        # æ­£å¸¸å‘½ä»¤è¡Œæ‰§è¡Œ
        exit(main())
